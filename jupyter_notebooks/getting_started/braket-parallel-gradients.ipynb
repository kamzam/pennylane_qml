{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computing gradients in parallel with Amazon Braket\n==================================================\n\n::: {.meta}\n:property=\\\"og:description\\\": Parallelize gradient calculations with\nAmazon Braket :property=\\\"og:image\\\":\n<https://pennylane.ai/qml/_images/pl-braket.png>\n:::\n\n::: {.related}\ntutorial\\_qaoa\\_intro Intro to QAOA vqe\\_parallel VQE with parallel QPUs\nwith Rigetti\n:::\n\n*Authors: Tom Bromley and Maria Schuld --- Posted: 08 December 2020.\nLast updated: 30 September 2021.*\n\nPennyLane integrates with [Amazon\nBraket](https://aws.amazon.com/braket/) to enable quantum machine\nlearning and optimization on high-performance simulators and quantum\nprocessing units (QPUs) through a range of\n[providers](https://aws.amazon.com/braket/hardware-providers/).\n\nIn PennyLane, Amazon Braket is accessed through the\n[PennyLane-Braket](https://amazon-braket-pennylane-plugin-python.readthedocs.io)\nplugin. The plugin can be installed using\n\n``` {.bash}\npip install amazon-braket-pennylane-plugin\n```\n\nA central feature of Amazon Braket is that its remote simulator can\nexecute multiple circuits in parallel. This capability can be harnessed\nin PennyLane during circuit training, which requires lots of variations\nof a circuit to be executed. Hence, the PennyLane-Braket plugin provides\na method for scalable optimization of large circuits with many\nparameters. This tutorial will explain the importance of this feature,\nallow you to benchmark it yourself, and explore its use for solving a\nscaled-up graph problem with QAOA.\n\n![](../_static/remote-multi-job-simulator.png){.align-center}\n\nWhy is training circuits so expensive?\n--------------------------------------\n\nQuantum-classical hybrid optimization of quantum circuits is the\nworkhorse algorithm of near-term quantum computing. It is not only\nfundamental for training variational quantum circuits, but also more\nbroadly for applications like quantum chemistry and quantum machine\nlearning. Today\\'s most powerful optimization algorithms rely on the\nefficient computation of gradients---which tell us how to adapt\nparameters a little bit at a time to improve the algorithm.\n\nCalculating the gradient involves multiple device executions: for each\ntrainable parameter we must execute our circuit on the device typically\n`more than once </glossary/parameter_shift>`{.interpreted-text\nrole=\"doc\"}. Reasonable applications involve many trainable parameters\n(just think of a classical neural net with millions of tunable weights).\nThe result is a huge number of device executions for each optimization\nstep.\n\n![](../_static/grad-circuits.png){.align-center}\n\nIn the standard `default.qubit` device, gradients are calculated in\nPennyLane through sequential device executions---in other words, all\nthese circuits have to wait in the same queue until they can be\nevaluated. This approach is simpler, but quickly becomes slow as we\nscale the number of parameters. Moreover, as the number of qubits, or\n\\\"width\\\", of the circuit is scaled, each device execution will slow\ndown and eventually become a noticeable bottleneck. In short---\\**the\nfuture of training quantum circuits relies on high-performance remote\nsimulators and hardware devices that are highly parallelized*\\*.\n\nFortunately, the PennyLane-Braket plugin provides a solution for\nscalable quantum circuit training by giving access to the Amazon Braket\nsimulator known as\n[SV1](https://docs.aws.amazon.com/braket/latest/developerguide/braket-devices.html).\nSV1 is a high-performance state vector simulator that is designed with\nparallel execution in mind. Together with PennyLane, we can use SV1 to\nrun in parallel all the circuits needed to compute a gradient!\n\nAccessing devices on Amazon Braket\n----------------------------------\n\nThe remote simulator and quantum hardware devices available on Amazon\nBraket can be found\n[here](https://docs.aws.amazon.com/braket/latest/developerguide/braket-devices.html).\nEach device has a unique identifier known as an\n[ARN](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).\nIn PennyLane, all remote Braket devices are accessed through a single\nPennyLane device named `braket.aws.qubit`, along with specification of\nthe corresponding ARN.\n\n::: {.note}\n::: {.title}\nNote\n:::\n\nTo access remote services on Amazon Braket, you must first create an\naccount on AWS and also follow the [setup\ninstructions](https://github.com/aws/amazon-braket-sdk-python#prerequisites)\nfor accessing Braket from Python.\n:::\n\nLet\\'s load the SV1 simulator in PennyLane with 25 qubits. We must\nspecify both the ARN and the address of the [S3\nbucket](https://aws.amazon.com/s3/) where results are to be stored:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_bucket = \"amazon-braket-Your-Bucket-Name\"  # the name of the bucket, keep the 'amazon-braket-' prefix and then include the bucket name\nmy_prefix = \"Your-Folder-Name\"  # the name of the folder in the bucket\ns3_folder = (my_bucket, my_prefix)\n\ndevice_arn = \"arn:aws:braket:::device/quantum-simulator/amazon/sv1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SV1 can now be loaded with the standard PennyLane\n`~.pennylane.device`{.interpreted-text role=\"func\"}:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\nfrom pennylane import numpy as np\n\nn_wires = 25\n\ndev_remote = qml.device(\n    \"braket.aws.qubit\",\n    device_arn=device_arn,\n    wires=n_wires,\n    s3_destination_folder=s3_folder,\n    parallel=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note the `parallel=True` argument. This setting allows us to unlock the\npower of parallel execution on SV1 for gradient calculations. We\\'ll\nalso load `default.qubit` for comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev_local = qml.device(\"default.qubit\", wires=n_wires)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that a local Braket device `braket.local.qubit` is also available.\nSee the\n[documentation](https://amazon-braket-pennylane-plugin-python.readthedocs.io)\nfor more details.\n\nBenchmarking circuit evaluation\n===============================\n\nWe will now compare the execution time for the remote Braket SV1 device\nand `default.qubit`. Our first step is to create a simple circuit:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def circuit(params):\n    for i in range(n_wires):\n        qml.RX(params[i], wires=i)\n    for i in range(n_wires):\n        qml.CNOT(wires=[i, (i + 1) % n_wires])\n\n    # Measure all qubits to make sure all's good with Braket\n    observables = [qml.PauliZ(n_wires - 1)] + [qml.Identity(i) for i in range(n_wires - 1)]\n    return qml.expval(qml.operation.Tensor(*observables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../_static/circuit.png){.align-center}\n\nIn this circuit, each of the 25 qubits has a controllable rotation. A\nfinal block of two-qubit CNOT gates is added to entangle the qubits.\nOverall, this circuit has 25 trainable parameters. Although not\nparticularly relevant for practical problems, we can use this circuit as\na testbed for our comparison.\n\nThe next step is to convert the above circuit into a PennyLane\n`~.pennylane.QNode`{.interpreted-text role=\"func\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "qnode_remote = qml.QNode(circuit, dev_remote)\nqnode_local = qml.QNode(circuit, dev_local)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.note}\n::: {.title}\nNote\n:::\n\nThe above uses `~.pennylane.QNode`{.interpreted-text role=\"func\"} to\nconvert the circuit. In other tutorials, you may have seen the\n`~.pennylane.qnode`{.interpreted-text role=\"func\"} decorator being used.\nThese approaches are interchangeable, but we use\n`~.pennylane.QNode`{.interpreted-text role=\"func\"} here because it\nallows us to pair the same circuit to different devices.\n:::\n\n::: {.warning}\n::: {.title}\nWarning\n:::\n\nRunning the contents of this tutorial will result in simulation fees\ncharged to your AWS account. We recommend monitoring your usage on the\nAWS dashboard.\n:::\n\nLet\\'s now compare the execution time between the two devices:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nparams = np.random.random(n_wires)\n\nt_0_remote = time.time()\nqnode_remote(params)\nt_1_remote = time.time()\n\nt_0_local = time.time()\nqnode_local(params)\nt_1_local = time.time()\n\nprint(\"Execution time on remote device (seconds):\", t_1_remote - t_0_remote)\nprint(\"Execution time on local device (seconds):\", t_1_local - t_0_local)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nExecution time on remote device (seconds): 3.5898206680030853\nExecution time on local device (seconds): 23.50668462700196\n```\n:::\n\nNice! These timings highlight the advantage of using the Amazon Braket\nSV1 device for simulations with large qubit numbers. In general,\nsimulation times scale exponentially with the number of qubits, but SV1\nis highly optimized and running on AWS remote servers. This allows SV1\nto outperform `default.qubit` in this 25-qubit example. The time you see\nin practice for the remote device will also depend on factors such as\nyour distance to AWS servers.\n\n::: {.note}\n::: {.title}\nNote\n:::\n\nGiven these timings, why would anyone want to use `default.qubit`? You\nshould consider using local devices when your circuit has few qubits. In\nthis regime, the latency times of communicating the circuit to a remote\nserver dominate over simulation times, allowing local simulators to be\nfaster.\n:::\n\nBenchmarking gradient calculations\n==================================\n\nNow let us compare the gradient-calculation times between the two\ndevices. Remember that when loading the remote device, we set\n`parallel=True`. This allows the multiple device executions required\nduring gradient calculations to be performed in parallel, so we expect\nthe remote device to be much faster.\n\nFirst, consider the remote device:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "d_qnode_remote = qml.grad(qnode_remote)\n\nt_0_remote_grad = time.time()\nd_qnode_remote(params)\nt_1_remote_grad = time.time()\n\nprint(\"Gradient calculation time on remote device (seconds):\", t_1_remote_grad - t_0_remote_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nGradient calculation time on remote device (seconds): 20.92005863400118\n```\n:::\n\nNow, the local device:\n\n::: {.warning}\n::: {.title}\nWarning\n:::\n\nEvaluating the gradient with `default.qubit` will take a long time,\nconsider commenting-out the following lines unless you are happy to\nwait.\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "d_qnode_local = qml.grad(qnode_local)\n\nt_0_local_grad = time.time()\nd_qnode_local(params)\nt_1_local_grad = time.time()\n\nprint(\"Gradient calculation time on local device (seconds):\", t_1_local_grad - t_0_local_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nGradient calculation time on local device (seconds): 941.8518133479993\n```\n:::\n\nWow, the local device needs around 15 minutes or more! Compare this to\nless than a minute spent calculating the gradient on SV1. This provides\na powerful lesson in parallelization.\n\nWhat if we had run on SV1 with `parallel=False`? It would have taken\naround 3 minutes---still faster than a local device, but much slower\nthan running SV1 in parallel.\n\nScaling up QAOA for larger graphs\n=================================\n\nThe quantum approximate optimization algorithm (QAOA) is a candidate\nalgorithm for near-term quantum hardware that can find approximate\nsolutions to combinatorial optimization problems such as graph-based\nproblems. We have seen in the main\n`QAOA tutorial<tutorial_qaoa_intro>`{.interpreted-text role=\"doc\"} how\nQAOA successfully solves the minimum vertex cover problem on a four-node\ngraph.\n\nHere, let\\'s be ambitious and try to solve the maximum cut problem on a\ntwenty-node graph! In maximum cut, the objective is to partition the\ngraph\\'s nodes into two groups so that the number of edges crossed or\n\\'cut\\' by the partition is maximized (see the diagram below). This\nproblem is NP-hard, so we expect it to be tough as we increase the\nnumber of graph nodes.\n\n![](../_static/max-cut.png){.align-center}\n\nLet\\'s first set the graph:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n\nnodes = n_wires = 20\nedges = 60\nseed = 1967\n\ng = nx.gnm_random_graph(nodes, edges, seed=seed)\npositions = nx.spring_layout(g, seed=seed)\n\nnx.draw(g, with_labels=True, pos=positions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../_static/20_node_graph.png){.align-center}\n\nWe will use the remote SV1 device to help us optimize our QAOA circuit\nas quickly as possible. First, the device is loaded again for 20 qubits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\n    \"braket.aws.qubit\",\n    device_arn=device_arn,\n    wires=n_wires,\n    s3_destination_folder=s3_folder,\n    parallel=True,\n    max_parallel=20,\n    poll_timeout_seconds=30,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note the specification of `max_parallel=20`. This means that up to `20`\ncircuits will be executed in parallel on SV1 (the default value is\n`10`).\n\n::: {.warning}\n::: {.title}\nWarning\n:::\n\nIncreasing the maximum number of parallel executions can result in a\ngreater rate of spending on simulation fees on Amazon Braket. The value\nmust also be set bearing in mind your service\n[quota](https://docs.aws.amazon.com/braket/latest/developerguide/braket-quotas.html).\n:::\n\nThe QAOA problem can then be set up following the standard pattern, as\ndiscussed in detail in the\n`QAOA tutorial<tutorial_qaoa_intro>`{.interpreted-text role=\"doc\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cost_h, mixer_h = qml.qaoa.maxcut(g)\nn_layers = 2\n\n\ndef qaoa_layer(gamma, alpha):\n    qml.qaoa.cost_layer(gamma, cost_h)\n    qml.qaoa.mixer_layer(alpha, mixer_h)\n\n\ndef circuit(params, **kwargs):\n    for i in range(n_wires):  # Prepare an equal superposition over all qubits\n        qml.Hadamard(wires=i)\n\n    qml.layer(qaoa_layer, n_layers, params[0], params[1])\n    return qml.expval(cost_h)\n\n\ncost_function = qml.QNode(circuit, dev)\noptimizer = qml.AdagradOptimizer(stepsize=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We\\'re now set up to train the circuit! Note, if you are training this\ncircuit yourself, you may want to increase the number of iterations in\nthe optimization loop and also investigate changing the number of QAOA\nlayers.\n\n::: {.warning}\n::: {.title}\nWarning\n:::\n\nThe following lines are computationally intensive. Remember that running\nit will result in simulation fees charged to your AWS account. We\nrecommend monitoring your usage on the AWS dashboard.\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nnp.random.seed(1967)\nparams = 0.01 * np.random.uniform(size=[2, n_layers], requires_grad=True)\niterations = 10\n\nfor i in range(iterations):\n    t0 = time.time()\n\n    params, cost_before = optimizer.step_and_cost(cost_function, params)\n\n    t1 = time.time()\n\n    if i == 0:\n        print(\"Initial cost:\", cost_before)\n    else:\n        print(f\"Cost at step {i}:\", cost_before)\n\n    print(f\"Completed iteration {i + 1}\")\n    print(f\"Time to complete iteration: {t1 - t0} seconds\")\n\nprint(f\"Cost at step {iterations}:\", cost_function(params))\n\nnp.save(\"params.npy\", params)\nprint(\"Parameters saved to params.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nInitial cost: -29.98570234095951\nCompleted iteration 1\nTime to complete iteration: 93.96246099472046 seconds\nCost at step 1: -27.154071768632154\nCompleted iteration 2\nTime to complete iteration: 84.80994844436646 seconds\nCost at step 2: -29.98726230006233\nCompleted iteration 3\nTime to complete iteration: 83.13504934310913 seconds\nCost at step 3: -29.999163153600062\nCompleted iteration 4\nTime to complete iteration: 85.61391234397888 seconds\nCost at step 4: -30.002158646044307\nCompleted iteration 5\nTime to complete iteration: 86.70688223838806 seconds\nCost at step 5: -30.012058444011906\nCompleted iteration 6\nTime to complete iteration: 83.26341080665588 seconds\nCost at step 6: -30.063709712612443\nCompleted iteration 7\nTime to complete iteration: 85.25566911697388 seconds\nCost at step 7: -30.32522304705352\nCompleted iteration 8\nTime to complete iteration: 83.55433392524719 seconds\nCost at step 8: -31.411030331978186\nCompleted iteration 9\nTime to complete iteration: 84.08745908737183 seconds\nCost at step 9: -33.87153965616938\nCompleted iteration 10\nTime to complete iteration: 87.4032838344574 seconds\nCost at step 10: -36.05424874438809\nParameters saved to params.npy\n```\n:::\n\nThis example shows us that a 20-qubit QAOA problem can be trained within\naround 1-2 minutes per iteration by using parallel executions on the\nAmazon Braket SV1 device to speed up gradient calculations. If this\nproblem were run on `default.qubit` without parallelization, we would\nexpect for training to take much longer.\n\nThe results of this optimization can be investigated by saving the\nparameters `here </demonstrations/braket/params.npy>`{.interpreted-text\nrole=\"download\"} to your working directory. See if you can analyze the\nperformance of this optimized circuit following a similar strategy to\nthe `QAOA tutorial<tutorial_qaoa_intro>`{.interpreted-text role=\"doc\"}.\nDid we find a large graph cut?\n\nAbout the authors\n=================\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}