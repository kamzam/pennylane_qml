{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantum natural SPSA optimizer\n==============================\n\n::: {.meta}\n:property=\\\"og:description\\\": Introduction to the Quantum natural SPSA\noptimizer, which reduces the number of quantum measurements in the\noptimization. :property=\\\"og:image\\\":\n<https://pennylane.ai/qml/_images/qnspsa_cover.png>\n:::\n\n::: {.related}\ntutorial\\_spsa Simultaneous perturbation stochastic approximation (SPSA)\noptimizer\n:::\n\n*Author: Yiheng Duan --- Posted: 18 July 2022. Last updated: 05\nSeptember 2022.*\n\nIn this tutorial, we show how we can implement the [quantum natural\nsimultaneous perturbation stochastic approximation (QN-SPSA)\noptimizer](https://quantum-journal.org/papers/q-2021-10-20-567/) from\nGacon et al. using PennyLane.\n\nVariational quantum algorithms (VQAs) are in close analogy to their\ncounterparts in classical machine learning. They both build a closed\noptimization loop and utilize an optimizer to iterate on the parameters.\nHowever, out-of-the-box classical gradient-based optimizers, such as\ngradient descent, are often unsatisfying for VQAs, as quantum\nmeasurements are notoriously expensive and gradient measurements for\nquantum circuits scale poorly with the system size.\n\nIn, Gacon et al. propose QN-SPSA, which is tailored for quantum\nalgorithms. In each optimization step, QN-SPSA executes only 2 quantum\ncircuits to estimate the gradient, and another 4 for the Fubini-Study\nmetric tensor, independent of the problem size. This preferred scaling\nmakes it a promising candidate for optimization tasks for noisy\nintermediate-scale quantum (NISQ) devices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Introduction\n============\n\nIn quantum machine learning (QML) and variational quantum algorithms\n(VQA), an optimizer does the following two tasks:\n\n-   It estimates the gradient of the cost function or other relevant\n    metrics at the current step.\n-   Based on the metrics, it decides the parameters for the next\n    iteration to reduce the cost.\n\nA simple example of such an optimizer is the vanilla gradient descent\n(GD), whose update rule is written as:\n\n$$\\mathbf{x}^{(t + 1)} = \\mathbf{x}^{(t)} - \\eta \\nabla f(\\mathbf{x}^{(t)}) \\label{eq:vanilla}\\tag{1},$$\n\nwhere $f(\\mathbf{x})$ is the loss function with input parameter\n$\\mathbf{x}$, while $\\eta$ is the learning rate. The superscript $t$\nstands for the $t$-th iteration step in the optimization. Here the\ngradient $\\nabla f$ is estimated dimension by dimension, requiring\n$O(d)$ quantum measurements ($d$ being the dimension of the parameter\nspace). As quantum measurements are expensive, this scaling makes GD\nimpractical for complicated high-dimensional circuits.\n\nTo address this unsatisfying scaling, the `simultaneous perturbation\nstochastic approximation (SPSA) optimizer </demos/tutorial_spsa>`{.interpreted-text\nrole=\"doc\"} replaces this dimensionwise gradient estimation with a\nstochastic one. In SPSA, a random direction\n$\\mathbf{h} \\in \\mathcal{U}(\\{-1, 1\\}^d)$ in the parameter space is\nsampled, where $\\mathcal{U}(\\{-1, 1\\}^d)$ is a $d$-dimensional discrete\nuniform distribution. The gradient component along this sampled\ndirection is then measured with a finite difference approach, with a\nperturbation step size $\\epsilon$:\n\n$$|{\\nabla}_{\\mathbf{h}}f(\\mathbf{x})| \\equiv\n\\mathbf{h}\\cdot {\\nabla}f(\\mathbf{x}) \\simeq \\frac{1}{2\\epsilon}\\big(f(\\mathbf{x} + \\epsilon \\mathbf{h}) - f(\\mathbf{x} - \\epsilon \\mathbf{h})\\big)\\label{eq:finite_diff}\\tag{2}.$$\n\nA stochastic gradient estimator\n$\\widehat{\\boldsymbol{\\nabla}}f(\\mathbf{x}, \\mathbf{h})_{SPSA}$ is then\nconstructed:\n\n$$\\widehat{\\nabla f}(\\mathbf{x}, \\mathbf{h})_{SPSA} = | {\\nabla}_{\\mathbf{h}}f(\\mathbf{x})|\\mathbf{h}\\label{eq:spsaGrad}\\tag{3}.$$\n\nWith the estimator, SPSA gives the following update rule:\n\n$$\\mathbf{x}^{(t + 1)} = \\mathbf{x}^{(t)} - \\eta \\widehat{\\nabla f}(\\mathbf{x}^{(t)}, \\mathbf{h}^{(t)})_{SPSA} \\label{eq:spsa}\\tag{4},$$\n\nwhere $\\mathbf{h}^{(t)}$ is sampled at each step. Although this\nstochastic approach cannot provide a stepwise unbiased gradient\nestimation, SPSA is proved to be especially effective when accumulated\nover multiple optimization steps.\n\nOn the other hand, `quantum natural gradient descent (QNG)\n</demos/tutorial_quantum_natural_gradient>`{.interpreted-text\nrole=\"doc\"} is a variant of gradient descent. It introduces the\nFubini-Study metric tensor $\\boldsymbol{g}$ into the optimization to\naccount for the structure of the non-Euclidean parameter space. The\n$d \\times d$ metric tensor is defined as\n\n$$\\boldsymbol{g}_{ij}(\\mathbf{x}) = -\\frac{1}{2} \\frac{\\partial}{\\partial \\mathbf{x}_i} \\frac{\\partial}{\\partial \\mathbf{x}_j} F(\\mathbf{x}', \\mathbf{x})\\biggr\\rvert_{\\mathbf{x}'=\\mathbf{x}},\\label{eq:fsTensor}\\tag{5}$$\n\nwhere\n$F(\\mathbf{x}', \\mathbf{x}) = \\bigr\\rvert\\langle \\phi(\\mathbf{x}') | \\phi(\\mathbf{x}) \\rangle \\bigr\\rvert ^ 2$,\nand $\\phi(\\mathbf{x})$ is the parameterized ansatz with input\n$\\mathbf{x}$. With the metric tensor, the update rule is rewritten as:\n\n$$\\mathbf{x}^{(t + 1)} = \\mathbf{x}^{(t)} - \\eta \\boldsymbol{g}^{-1}(\\mathbf{x}^{(t)}) \\nabla f(\\mathbf{x}^{(t)}) \\label{eq:qn}\\tag{6}.$$\n\nWhile the introduction of the metric tensor helps to find better minima\nand allows for faster convergence, the algorithm is not as scalable due\nto the number of measurements required to estimate $\\boldsymbol{g}$.\n\nQN-SPSA manages to combine the merits of QNG and SPSA by estimating both\nthe gradient and the metric tensor stochastically. The gradient is\nestimated in the same fashion as the SPSA algorithm, while the\nFubini-Study metric is computed by a second-order process with another\ntwo stochastic perturbations:\n\n$$\\widehat{\\boldsymbol{g}}(\\mathbf{x}, \\mathbf{h}_1, \\mathbf{h}_2)_{SPSA} = \\frac{\\delta F }{8 \\epsilon^2}\\Big(\\mathbf{h}_1 \\mathbf{h}_2^\\intercal + \\mathbf{h}_2 \\mathbf{h}_1^\\intercal\\Big) \\label{eq:fs_qnspsa}\\tag{7},$$\n\nwhere\n\n$$\\delta F = F(\\mathbf{x, \\mathbf{x} + \\epsilon \\mathbf{h}_1} + \\epsilon \\mathbf{h}_2) - F (\\mathbf{x, \\mathbf{x} + \\epsilon \\mathbf{h}_1}) - F(\\mathbf{x, \\mathbf{x} - \\epsilon \\mathbf{h}_1} + \\epsilon \\mathbf{h}_2) + F(\\mathbf{x, \\mathbf{x} - \\epsilon \\mathbf{h}_1})\\label{eq:deltaf}\\tag{8},$$\n\nand $\\mathbf{h}_1, \\mathbf{h}_2 \\in \\mathcal{U}(\\{-1, 1\\}^d)$ are two\nrandomly sampled directions.\n\nWith equation (7), QN-SPSA provides the update rule\n\n$$\\mathbf{x}^{(t + 1)} = \\mathbf{x}^{(t)} - \\eta \\widehat{\\boldsymbol{g}}^{-1}(\\mathbf{x}^{(t)}, \\mathbf{h}_1^{(t)}, \\mathbf{h}_2^{(t)})_{SPSA} \\widehat{\\nabla f}(\\mathbf{x}^{(t)}, \\mathbf{h}^{(t)})_{SPSA} \\label{eq:qnspsa}\\tag{9}.$$\n\nIn each optimization step $t$, one will need to randomly sample 3\nperturbation directions\n$\\mathbf{h}^{(t)}, \\mathbf{h}_1^{(t)}, \\mathbf{h}_2^{(t)}$. Equation (9)\nis then applied to compute the parameters for the $(t + 1)$-th step\naccordingly. This $O(1)$ update rule fits into NISQ devices well.\n\nNumerical stability\n===================\n\nThe QN-SPSA update rule given in equation (9) is highly stochastic and\nmay not behave well numerically. In practice, a few tricks are applied\nto ensure the method's numerical stability:\n\nAveraging on the Fubini-Study metric tensor\n\n:   A running average is taken on the metric tensor estimated from\n    equation (7) at each step $t$:\n\n    $$\\bar{\\boldsymbol{g}}^{(t)}(\\mathbf{x}) = \\frac{1}{t + 1} \\Big(\\sum_{i=1}^{t}\\widehat{\\boldsymbol{g}}(\\mathbf{x}, \\mathbf{h}_1^{(i)}, \\mathbf{h}_2^{(i)})_{SPSA} + \\boldsymbol{g}^{(0)}\\Big)\\label{eq:tensorRunningAvg}\\tag{10} ,$$\n\n    where the initial guess $\\boldsymbol{g}^{(0)}$ is set to be the\n    identity matrix.\n\nFubini-Study metric tensor regularization\n\n:   To ensure the positive semidefiniteness of the metric tensor near a\n    minimum, the running average in equation (10) is regularized:\n\n    $$\\bar{\\boldsymbol{g}}^{(t)}_{reg}(\\mathbf{x}) = \\sqrt{\\bar{\\boldsymbol{g}}^{(t)}(\\mathbf{x}) \\bar{\\boldsymbol{g}}^{(t)}(\\mathbf{x})} + \\beta \\mathbb{I}\\label{eq:tensor_reg}\\tag{11},$$\n\n    where $\\beta$ is the regularization coefficient. We can consider\n    $\\beta$ as a hyperparameter and choose a suitable value by trial and\n    error. If $\\beta$ is too small, it cannot protect the positive\n    semidefiniteness of $\\bar{\\boldsymbol{g}}_{reg}$. If $\\beta$ is too\n    large, it will wipe out the information from the Fubini-Study metric\n    tensor, reducing QN-SPSA to the first order SPSA.\n\n    With equation (11), the QN-SPSA update rule we implement in code\n    reads\n\n    $$\\mathbf{x}^{(t + 1)} = \\mathbf{x}^{(t)} - \\eta (\\bar{\\boldsymbol{g}}^{(t)}_{reg})^{-1}(\\mathbf{x}^{(t)}) \\widehat{\\nabla f}(\\mathbf{x}^{(t)}, \\mathbf{h}^{(t)})_{SPSA} \\label{eq:qnspsa_reg}\\tag{12}.$$\n\nBlocking condition on the parameter update\n\n:   A blocking condition is applied onto the parameter update. The\n    optimizer only accepts updates that lead to a loss value no larger\n    than the one before update, plus a tolerance. Reference suggests\n    choosing a tolerance that is twice the standard deviation of the\n    loss.\n\nImplementation\n==============\n\nWe are now going to implement the QN-SPSA optimizer with all the tricks\nfor numerical stability included, and test it with a toy optimization\nproblem.\n\nLet's first set up the toy example to optimize. We use a [QAOA max cut\nproblem](https://pennylane.readthedocs.io/en/stable/code/api/pennylane.qaoa.cost.maxcut.html)\nas our testing ground.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# initialize a graph for the max cut problem\nimport networkx as nx\nfrom matplotlib import pyplot as plt\nimport pennylane as qml\nfrom pennylane import qaoa\n\nnodes = n_qubits = 4\nedges = 4\nseed = 121\n\ng = nx.gnm_random_graph(nodes, edges, seed=seed)\ncost_h, mixer_h = qaoa.maxcut(g)\ndepth = 2\n# define device to be the PennyLane lightning local simulator\ndev = qml.device(\"lightning.qubit\", wires=n_qubits, shots=1000)\n\n\ndef qaoa_layer(gamma, alpha):\n    qaoa.cost_layer(gamma, cost_h)\n    qaoa.mixer_layer(alpha, mixer_h)\n\n\ndef qaoa_circuit(params, n_qubits, depth):\n    # initialize all qubits into +X eigenstate.\n    for w in range(n_qubits):\n        qml.Hadamard(wires=w)\n    gammas = params[0]\n    alphas = params[1]\n    # stack building blocks for depth times.\n    qml.layer(qaoa_layer, depth, gammas, alphas)\n\n\n# define ansatz and loss function\n@qml.qnode(dev)\ndef cost_function(params):\n    qaoa_circuit(params, n_qubits, depth)\n    return qml.expval(cost_h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's confirm this circuit works. We generate a set of random parameters\nas input, and check if the QNode `cost_function` for the circuit can be\nexecuted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pennylane import numpy as np\n\n# initialize a random parameter tensor with shape (2, depth), scaled\n# to [-pi, pi)\nparams_curr = 2 * np.pi * (np.random.rand(2, depth) - 0.5)\nprint(\"Input parameter shape:\", params_curr.shape)\nprint(\"Loss value:\", cost_function(params_curr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nInput parameter shape: (2, 2)\nLoss value: -1.5099999999999998\n```\n:::\n\nWith the problem set up, we will for now focus on implementing a\nsingle-step update of the QN-SPSA. Given the current parameters\n`params_curr`, we would like to compute the parameters for the next step\n`params_next`. We first define a few necessary hyperparameters and\nglobal variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\n\n# step index\nk = 1\n\n# random seed for sampling the perturbation directions\nseed = 1\nrandom.seed(seed)\n\n# perturbation size for the finite difference calculation\nfinite_diff_step = 1e-2\n\n# regularization coefficient for the metric tensor\nregularization = 1e-3\n\n# learning rate\nlr = 1e-2\n\n# initialize the metric tensor to be an identity matrix\nparams_number = params_curr.size\nmetric_tensor = np.identity(params_number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As both the gradient estimator and the metric tensor estimator involve\ngetting random perturbation directions, we first implement a sampling\nfunction that we call `get_perturbation_direction`. The function takes\nthe input parameter to the circuit ansatz, and returns a direction\ntensor of the same shape. The direction tensor is sampled from a\ndiscrete uniform distribution $\\mathcal{U}(\\{-1, 1\\}^d)$ using\n`random.choices`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_perturbation_direction(params):\n    param_number = len(params) if isinstance(params, list) else params.size\n    sample_list = random.choices([-1, 1], k=param_number)\n    direction = np.array(sample_list).reshape(params.shape)\n    return direction\n\n\nprint(get_perturbation_direction(params_curr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\n[[-1  1]\n[ 1 -1]]\n```\n:::\n\nWith this function at our disposal, we implement the gradient estimator\n`get_grad` following equation (2):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_grad(params_curr):\n    grad_dir = get_perturbation_direction(params_curr)\n    # apply the perturbation\n    params_forward = params_curr + finite_diff_step * grad_dir\n    params_backward = params_curr - finite_diff_step * grad_dir\n    # measured stochastic gradient\n    loss_forward = cost_function(params_forward)\n    loss_backward = cost_function(params_backward)\n    grad = (loss_forward - loss_backward) / (2 * finite_diff_step) * grad_dir\n    return grad\n\n\ngrad = get_grad(params_curr)\nprint(\"Estimated SPSA gradient:\\n\", grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nEstimated SPSA gradient:\n[[-3.05 -3.05]\n[ 3.05  3.05]]\n```\n:::\n\nTo estimate the raw stochastic metric tensor\n$\\widehat{\\boldsymbol{g}}(\\mathbf{x}, \\mathbf{h}_1, \\mathbf{h}_2)_{SPSA}$\nfrom equation (7), we will first need to measure the state overlap\n$F(\\mathbf{x}_1, \\mathbf{x}_2) = \\bigr\\rvert\\langle \\phi(\\mathbf{x}_1) | \\phi(\\mathbf{x}_2) \\rangle \\bigr\\rvert ^ 2$.\nWe denote the unitary transformation forming the ansatz with $U$; that\nis, $\\rvert\\phi(\\mathbf{x})\\rangle = U(\\mathbf{x}) \\rvert0\\rangle$.\nApplying the adjoint operation $U^{\\dagger}(\\mathbf{x}_2)$ on to the\nansatz state $\\rvert\\phi(\\mathbf{x}_1)\\rangle$ followed with a\nmeasurement in the computational basis then does the trick. The state\noverlap equals the probability of a $\\rvert00...0\\rangle$ measurement\noutcome. Note that this circuit measuring the state overlap doubles the\ncircuit depth of the ansatz, and therefore has longer execution time and\nexperiences more accumulated noise from the device. The function\n`get_state_overlap` returns a state overlap value between 0 (minimum\noverlap) and 1 (perfect overlap).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from copy import copy\n\n\ndef get_operations(qnode, params):\n    qnode.construct([params], {})\n    return qnode.tape.operations\n\n\ndef get_overlap_tape(qnode, params1, params2):\n    op_forward = get_operations(qnode, params1)\n    op_inv = get_operations(qnode, params2)\n\n    with qml.tape.QuantumTape() as tape:\n        for op in op_forward:\n            qml.apply(op)\n        for op in reversed(op_inv):\n            qml.adjoint(copy(op))\n        qml.probs(wires=qnode.tape.wires.labels)\n    return tape\n\n\ndef get_state_overlap(tape):\n    return qml.execute([tape], dev, None)[0][0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's do a quick sanity check on the state overlap calculation. From the\nfollowing cell, we can see that the overlap of a state with itself is 1,\nwhile the number for two states from random inputs can vary between 0\nand 1. This means `get_state_overlap` function works!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tape = get_overlap_tape(cost_function, params_curr, params_curr)\nprint(\"Perfect overlap: \", get_state_overlap(tape))\n\ntape = get_overlap_tape(cost_function, params_curr, 2 * np.pi * (np.random.rand(2, depth) - 0.5))\nprint(\"Random state overlap: \", get_state_overlap(tape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nPerfect overlap:  1.0\nRandom state overlap:  0.599\n```\n:::\n\nNow that we have confirmed our implementation of the state overlap, we\ncan proceed to compute the raw stochastic metric tensor\n$\\widehat{\\boldsymbol{g}}(\\mathbf{x}, \\mathbf{h}_1, \\mathbf{h}_2)_{SPSA}$.\nWith the function `get_raw_tensor_metric`, we sample two perturbations\nwith `get_perturbation_direction` independently and estimate the raw\nmetric tensor with equations (8) and (7).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_raw_tensor_metric(params_curr):\n\n    dir1 = get_perturbation_direction(params_curr)\n    dir2 = get_perturbation_direction(params_curr)\n    perturb1 = dir1 * finite_diff_step\n    perturb2 = dir2 * finite_diff_step\n    dir_vec1 = dir1.reshape(-1)\n    dir_vec2 = dir2.reshape(-1)\n    tapes = [\n        get_overlap_tape(cost_function, params_curr, params_curr + perturb1 + perturb2),\n        get_overlap_tape(cost_function, params_curr, params_curr + perturb1),\n        get_overlap_tape(cost_function, params_curr, params_curr - perturb1 + perturb2),\n        get_overlap_tape(cost_function, params_curr, params_curr - perturb1),\n    ]\n\n    tensor_finite_diff = (\n        get_state_overlap(tapes[0])\n        - get_state_overlap(tapes[1])\n        - get_state_overlap(tapes[2])\n        + get_state_overlap(tapes[3])\n    )\n\n    metric_tensor_raw = (\n        -(np.tensordot(dir_vec1, dir_vec2, axes=0) + np.tensordot(dir_vec2, dir_vec1, axes=0))\n        * tensor_finite_diff\n        / (8 * finite_diff_step * finite_diff_step)\n    )\n    return metric_tensor_raw\n\n\nmetric_tensor_raw = get_raw_tensor_metric(params_curr)\nprint(\"Raw estimated metric tensor:\\n\", metric_tensor_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nRaw estimated metric tensor:\n[[ 2.5  0.  -2.5  2.5]\n[ 0.  -2.5  0.   0. ]\n[-2.5  0.   2.5 -2.5]\n[ 2.5  0.  -2.5  2.5]]\n```\n:::\n\nNow, let\\'s apply the running average in equation (10), and the\nregularization in equation (11):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.linalg import sqrtm\n\nmetric_tensor_avg = 1 / (k + 1) * metric_tensor_raw + k / (k + 1) * metric_tensor\ntensor_reg = np.real(sqrtm(np.matmul(metric_tensor_avg, metric_tensor_avg)))\n# update metric tensor\nmetric_tensor = ((tensor_reg + regularization * np.identity(metric_tensor.shape[0]))) / (\n    1 + regularization\n)\n# update step index\nk += 1\nprint(\"Updated metric tensor after the step:\\n\", metric_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nUpdated metric tensor after the step:\n[[ 1.74925075  0.         -1.24875125  1.24875125]\n[ 0.          0.75024975  0.          0.        ]\n[-1.24875125  0.          1.74925075 -1.24875125]\n[ 1.24875125  0.         -1.24875125  1.74925075]]\n```\n:::\n\nEquation (12) requires computing the inverse of the metric tensor. A\nnumerically more stable approach is to solve the equivalent linear\nequation for $\\mathbf{x}^{(t + 1)}$:\n\n$$\\bar{\\boldsymbol{g}}^{(t)}_{reg}(\\mathbf{x}^{(t)})\\big( \\mathbf{x}^{(t)} - \\mathbf{x}^{(t + 1)}\\big) =  \\eta  \\widehat{\\nabla f}(\\mathbf{x}^{(t)}, \\mathbf{h}^{(t)})_{SPSA} \\label{eq:lin_solver}\\tag{13}.$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_next_params(params, gradient):\n    grad_vec, params_vec = gradient.reshape(-1), params.reshape(-1)\n    new_params_vec = np.linalg.solve(\n        metric_tensor,\n        (-lr * grad_vec + np.matmul(metric_tensor, params_vec)),\n    )\n    return new_params_vec.reshape(params.shape)\n\n\nparams_next = get_next_params(params_curr, grad)\nprint(\"Next parameters:\\n\", params_next)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nNext parameters:\n[[-1.03117138 -0.54824992]\n[-2.03318839  0.80331292]]\n```\n:::\n\nNow, it is the time to apply the blocking condition. Let's first try the\nproposal in to use twice the sample standard deviation of the loss at\nthe current step as the tolerance. To collect such a sample, we need to\nrepeat the QNode execution for the loss `cost_function` for, say, 10\ntimes. The straightforward implementation goes as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss_next = cost_function(params_next)\n\nrepeats = 10\nloss_curr_list = np.zeros(repeats)\nfor i in range(repeats):\n    loss_curr_list[i] = cost_function(params_curr)\n\ntol = 2 * loss_curr_list.std()\nloss_curr = loss_curr_list.mean()\n\n# block updates that lead to significant increase\n# of the loss value\nif loss_curr + tol < loss_next:\n    params_next = params_curr\nprint(\"Next parameters after blocking:\\n\", params_next)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nNext parameters after blocking:\n[[-1.03117138 -0.54824992]\n[-2.03318839  0.80331292]]\n```\n:::\n\nAs quantum measurements are generally expensive, computing the tolerance\nthis way adds significant overhead to the QN-SPSA optimizer. To be\nspecific, in each step of the optimization, QN-SPSA only requires\nexecuting 2 circuits for the gradient, and 4 for the metric tensor. Yet\nin the approach above, there are an additional 10 (from the repeat\nnumber) + 1 circuits required to apply the blocking.\n\nTo address this issue, we propose to define the tolerance as the\nstandard deviation of the loss values of the past $N$ steps instead,\nwhere $N$ is a hyperparameter we choose. The intuition here is that when\nthe optimizer is working in a fast-descending regime, the blocking\ncondition is unlikely to be triggered, as new loss values are often\nsmaller than the previous ones. On the other hand, when the optimizer is\nworking in a rather flat energy landscape, losses from the past $N$\nsteps could be very similar to the current loss value. In this regime,\nthe tolerance defined from both approaches should be close.\n\nThe implementation of this new tolerance is shown below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# define number of steps to track\nhistory_length = 5\n# track the past losses in an array\nlast_n_steps = np.zeros(history_length)\n\n\n# stepwise update\nloss_curr = cost_function(params_curr)\nloss_next = cost_function(params_next)\n\n# k has been updated above\nind = (k - 2) % history_length\nlast_n_steps[ind] = loss_curr\n\ntol = 2 * last_n_steps.std() if k > history_length else 2 * last_n_steps[: k - 1].std()\n\nif loss_curr + tol < loss_next:\n    params_next = params_curr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The efficacy of this new tolerance definition is confirmed by\nreproducing the experiment on QN-SPSA in Fig. 1(b) from reference. In\nthe following figure, we show the performance of the optimizer with the\ntwo tolerance definitions for an 11-qubit system. The shaded areas are\nthe profiles of 25 trials of the experiment. One can confirm the\npast-$N$-step ($N=5$ for the plot) standard deviation works just as\nwell. With the new choice of the tolerance, for each step, the QN-SPSA\nwill only need to execute 2 (for gradient) + 4 (for metric tensor) + 2\n(for the current and the next-step loss) = 8 circuits. In practice, we\nmeasure a 50% reduction in the stepwise optimization time.\n\nThe test is done with [Amazon Braket Hybrid\nJobs](https://docs.aws.amazon.com/braket/latest/developerguide/braket-jobs.html),\nas it is a handy tool to scale up experiments systematically. We will\nshow how to do that towards the end of the tutorial.\n\n![](../demonstrations/qnspsa/qnspsa_new_tol.png){.align-center\nwidth=\"80.0%\"}\n\nSimilarly, with Hybrid Jobs, we can confirm that blocking is necessary\nfor this second-order SPSA optimizer, though it does not make much\ndifference for SPSA. Here, the envelope of the QN-SPSA curves without\nblocking is not plotted since it is too noisy to visualize. SPSA is\nimplemented by replacing the metric tensor with an identity matrix.\n\n![](../demonstrations/qnspsa/qnspsa_blocking.png){.align-center\nwidth=\"80.0%\"}\n\nEfficiency improvement\n======================\n\nLet's do a deep dive on how to further improve the execution efficiency\nof the code. In the code example above, we compute gradient, metric\ntensor, and the loss values through individual calls on the\n`QNode.__call__()` function (in this example, `cost_function()`). In a\nhandwavy argument, each `QNode.__call__()` does the following two\nthings: (1) it constructs a tape with the given parameters, and (2)\ncalls `qml.execute()` to execute the single tape.\n\nHowever, in this use case, the better practice is to group the tapes and\ncall one `qml.execute()` on all the tapes. This practice utilizes the\nbatch execution feature from PennyLane, and has a few potential\nadvantages. Some simulators provide parallelization support, so that the\ngrouped tapes can be executed simutaneously. As an example, utilizing\nthe [task\nbatching](https://docs.aws.amazon.com/braket/latest/developerguide/braket-batching-tasks.html?tag=local002)\nfeature from the Braket SV1 simulator, we are able to reduce the\noptimization time by 75% for large circuits. For quantum hardware,\nsending tapes in batches could also enable further efficiency\nimprovement in circuit compilation.\n\nWith this rewriting, the complete optimizer class is provided in the\nfollowing cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\nimport pennylane as qml\nfrom pennylane import numpy as np\nfrom scipy.linalg import sqrtm\nimport warnings\n\n\nclass QNSPSA:\n    \"\"\"Quantum natural SPSA optimizer. Refer to https://quantum-journal.org/papers/q-2021-10-20-567/\n    for a detailed description of the methodology. When disable_metric_tensor\n    is set to be True, the metric tensor estimation is disabled, and QNSPSA is\n    reduced to be a SPSA optimizer.\n\n    Args:\n        stepsize (float): The learn rate.\n        regularization (float): Regularitzation term to the Fubini-Study\n            metric tensor for numerical stability.\n        finite_diff_step (float): step size to compute the finite difference\n            gradient and the Fubini-Study metric tensor.\n        resamplings (int): The number of samples to average for each parameter\n            update.\n        blocking (boolean): When set to be True, the optimizer only accepts\n            updates that lead to a loss value no larger than the loss value\n            before update, plus a tolerance. The tolerance is set with the\n            parameter history_length.\n        history_length (int): When blocking is True, the tolerance is set to be\n            the average of the cost values in the last history_length steps.\n        disable_metric_tensor (boolean): When set to be True, the optimizer is\n            reduced to be a (1st-order) SPSA optimizer.\n        seed (int): Seed for the random sampling.\n    \"\"\"\n\n    def __init__(\n        self,\n        stepsize=1e-3,\n        regularization=1e-3,\n        finite_diff_step=1e-2,\n        resamplings=1,\n        blocking=True,\n        history_length=5,\n        disable_metric_tensor=False,\n        seed=None,\n    ):\n        self.stepsize = stepsize\n        self.reg = regularization\n        self.finite_diff_step = finite_diff_step\n        self.metric_tensor = None\n        self.k = 1\n        self.resamplings = resamplings\n        self.blocking = blocking\n        self.last_n_steps = np.zeros(history_length)\n        self.history_length = history_length\n        self.disable_metric_tensor = disable_metric_tensor\n        random.seed(seed)\n        return\n\n    def step(self, cost, params):\n        \"\"\"Update trainable arguments with one step of the optimizer.\n\n        .. warning::\n            When blocking is set to be True, use step_and_cost instead, as loss\n            measurements are required for the updates for the case.\n\n        Args:\n            cost (qml.QNode): the QNode wrapper for the objective function for\n            optimization\n            params (np.array): Parameter before update.\n\n        Returns:\n            np.array: The new variable values after step-wise update.\n        \"\"\"\n        if self.blocking:\n            warnings.warn(\n                \"step_and_cost() instead of step() is called when \"\n                \"blocking is turned on, as the step-wise loss value \"\n                \"is required by the algorithm.\",\n                stacklevel=2,\n            )\n            return self.step_and_cost(cost, params)[0]\n\n        if self.disable_metric_tensor:\n            return self.__step_core_first_order(cost, params)\n        return self.__step_core(cost, params)\n\n    def step_and_cost(self, cost, params):\n        \"\"\"Update trainable parameters with one step of the optimizer and return\n        the corresponding objective function value after the step.\n\n        Args:\n            cost (qml.QNode): the QNode wrapper for the objective function for\n                optimization\n            params (np.array): Parameter before update.\n\n        Returns:\n            tuple[np.array, float]: the updated parameter and the objective\n                function output before the step.\n        \"\"\"\n        params_next = (\n            self.__step_core_first_order(cost, params)\n            if self.disable_metric_tensor\n            else self.__step_core(cost, params)\n        )\n\n        if not self.blocking:\n            loss_curr = cost(params)\n            return params_next, loss_curr\n        params_next, loss_curr = self.__apply_blocking(cost, params, params_next)\n        return params_next, loss_curr\n\n    def __step_core(self, cost, params):\n        # Core function that returns the next parameters before applying blocking.\n        grad_avg = np.zeros(params.shape)\n        tensor_avg = np.zeros((params.size, params.size))\n        for i in range(self.resamplings):\n            grad_tapes, grad_dir = self.__get_spsa_grad_tapes(cost, params)\n            metric_tapes, tensor_dirs = self.__get_tensor_tapes(cost, params)\n            raw_results = qml.execute(grad_tapes + metric_tapes, cost.device, None)\n            grad = self.__post_process_grad(raw_results[:2], grad_dir)\n            metric_tensor = self.__post_process_tensor(raw_results[2:], tensor_dirs)\n            grad_avg = grad_avg * i / (i + 1) + grad / (i + 1)\n            tensor_avg = tensor_avg * i / (i + 1) + metric_tensor / (i + 1)\n\n        self.__update_tensor(tensor_avg)\n        return self.__get_next_params(params, grad_avg)\n\n    def __step_core_first_order(self, cost, params):\n        # Reduced core function that returns the next parameters with SPSA rule.\n        # Blocking not applied.\n        grad_avg = np.zeros(params.shape)\n        for i in range(self.resamplings):\n            grad_tapes, grad_dir = self.__get_spsa_grad_tapes(cost, params)\n            raw_results = qml.execute(grad_tapes, cost.device, None)\n            grad = self.__post_process_grad(raw_results, grad_dir)\n            grad_avg = grad_avg * i / (i + 1) + grad / (i + 1)\n        return params - self.stepsize * grad_avg\n\n    def __post_process_grad(self, grad_raw_results, grad_dir):\n        # With the quantum measurement results from the 2 gradient tapes,\n        # compute the estimated gradient. Returned gradient is a tensor\n        # of the same shape with the input parameter tensor.\n        loss_forward, loss_backward = grad_raw_results\n        grad = (loss_forward - loss_backward) / (2 * self.finite_diff_step) * grad_dir\n        return grad\n\n    def __post_process_tensor(self, tensor_raw_results, tensor_dirs):\n        # With the quantum measurement results from the 4 metric tensor tapes,\n        # compute the estimated raw metric tensor. Returned raw metric tensor\n        # is a tensor of shape (d x d), d being the dimension of the input parameter\n        # to the ansatz.\n        tensor_finite_diff = (\n            tensor_raw_results[0][0][0]\n            - tensor_raw_results[1][0][0]\n            - tensor_raw_results[2][0][0]\n            + tensor_raw_results[3][0][0]\n        )\n        metric_tensor = (\n            -(\n                np.tensordot(tensor_dirs[0], tensor_dirs[1], axes=0)\n                + np.tensordot(tensor_dirs[1], tensor_dirs[0], axes=0)\n            )\n            * tensor_finite_diff\n            / (8 * self.finite_diff_step * self.finite_diff_step)\n        )\n        return metric_tensor\n\n    def __get_next_params(self, params, gradient):\n        grad_vec, params_vec = gradient.reshape(-1), params.reshape(-1)\n        new_params_vec = np.linalg.solve(\n            self.metric_tensor,\n            (-self.stepsize * grad_vec + np.matmul(self.metric_tensor, params_vec)),\n        )\n        return new_params_vec.reshape(params.shape)\n\n    def __get_perturbation_direction(self, params):\n        param_number = len(params) if isinstance(params, list) else params.size\n        sample_list = random.choices([-1, 1], k=param_number)\n        direction = np.array(sample_list).reshape(params.shape)\n        return direction\n\n    def __get_spsa_grad_tapes(self, cost, params):\n        # Returns the 2 tapes along with the sampled direction that will be\n        # used to estimate the gradient per optimization step. The sampled\n        # direction is of the shape of the input parameter.\n        direction = self.__get_perturbation_direction(params)\n        cost.construct([params + self.finite_diff_step * direction], {})\n        tape_forward = cost.tape.copy(copy_operations=True)\n        cost.construct([params - self.finite_diff_step * direction], {})\n        tape_backward = cost.tape.copy(copy_operations=True)\n        return [tape_forward, tape_backward], direction\n\n    def __update_tensor(self, tensor_raw):\n        tensor_avg = self.__get_tensor_moving_avg(tensor_raw)\n        tensor_regularized = self.__regularize_tensor(tensor_avg)\n        self.metric_tensor = tensor_regularized\n        self.k += 1\n\n    def __get_tensor_tapes(self, cost, params):\n        # Returns the 4 tapes along with the 2 sampled directions that will be\n        # used to estimate the raw metric tensor per optimization step. The sampled\n        # directions are 1d vectors of the length of the input parameter dimension.\n        dir1 = self.__get_perturbation_direction(params)\n        dir2 = self.__get_perturbation_direction(params)\n        perturb1 = dir1 * self.finite_diff_step\n        perturb2 = dir2 * self.finite_diff_step\n        dir_vecs = dir1.reshape(-1), dir2.reshape(-1)\n\n        tapes = [\n            self.__get_overlap_tape(cost, params, params + perturb1 + perturb2),\n            self.__get_overlap_tape(cost, params, params + perturb1),\n            self.__get_overlap_tape(cost, params, params - perturb1 + perturb2),\n            self.__get_overlap_tape(cost, params, params - perturb1),\n        ]\n        return tapes, dir_vecs\n\n    def __get_overlap_tape(self, cost, params1, params2):\n        op_forward = self.__get_operations(cost, params1)\n        op_inv = self.__get_operations(cost, params2)\n\n        with qml.tape.QuantumTape() as tape:\n            for op in op_forward:\n                qml.apply(op)\n            for op in reversed(op_inv):\n                op.adjoint()\n            qml.probs(wires=cost.tape.wires.labels)\n        return tape\n\n    def __get_operations(self, cost, params):\n        # Given a QNode, returns the list of operations before the measurement.\n        cost.construct([params], {})\n        return cost.tape.operations\n\n    def __get_tensor_moving_avg(self, metric_tensor):\n        # For numerical stability: averaging on the Fubini-Study metric tensor.\n        if self.metric_tensor is None:\n            self.metric_tensor = np.identity(metric_tensor.shape[0])\n        return self.k / (self.k + 1) * self.metric_tensor + 1 / (self.k + 1) * metric_tensor\n\n    def __regularize_tensor(self, metric_tensor):\n        # For numerical stability: Fubini-Study metric tensor regularization.\n        tensor_reg = np.real(sqrtm(np.matmul(metric_tensor, metric_tensor)))\n        return (tensor_reg + self.reg * np.identity(metric_tensor.shape[0])) / (1 + self.reg)\n\n    def __apply_blocking(self, cost, params_curr, params_next):\n        # For numerical stability: apply the blocking condition on the parameter update.\n        cost.construct([params_curr], {})\n        tape_loss_curr = cost.tape.copy(copy_operations=True)\n        cost.construct([params_next], {})\n        tape_loss_next = cost.tape.copy(copy_operations=True)\n\n        loss_curr, loss_next = qml.execute([tape_loss_curr, tape_loss_next], cost.device, None)\n        # self.k has been updated earlier.\n        ind = (self.k - 2) % self.history_length\n        self.last_n_steps[ind] = loss_curr\n\n        tol = (\n            2 * self.last_n_steps.std()\n            if self.k > self.history_length\n            else 2 * self.last_n_steps[: self.k - 1].std()\n        )\n\n        if loss_curr + tol < loss_next:\n            params_next = params_curr\n        return params_next, loss_curr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see how it performs on our QAOA example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "opt = QNSPSA(stepsize=5e-2)\nparams_init = 2 * np.pi * (np.random.rand(2, depth) - 0.5)\nparams = params_init\nfor i in range(300):\n    params, loss = opt.step_and_cost(cost_function, params)\n    if i % 40 == 0:\n        print(f\"Step {i}: cost = {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nStep 0: cost = -2.0730\nStep 40: cost = -2.5390\nStep 80: cost = -2.7240\nStep 120: cost = -2.6760\nStep 160: cost = -2.7540\nStep 200: cost = -2.7060\nStep 240: cost = -2.8110\nStep 280: cost = -2.7930\n```\n:::\n\nThe optimizer performs reasonably well: the loss drops over optimization\nsteps and converges finally. We then reproduce the benchmarking test\nbetween the gradient descent, quantum natural gradient descent, SPSA and\nQN-SPSA in Fig. 1(b) of reference with the following job. You can find a\nmore detailed version of the example in this\n[notebook](https://github.com/aws/amazon-braket-examples/blob/main/examples/hybrid_jobs/6_QNSPSA_optimizer_with_embedded_simulator/qnspsa_with_embedded_simulator.ipynb),\nwith its dependencies in the [source\\_scripts]{.title-ref}\n[folder](https://github.com/aws/amazon-braket-examples/blob/main/examples/hybrid_jobs/6_QNSPSA_optimizer_with_embedded_simulator/source_scripts/).\n\n::: {.note}\n::: {.title}\nNote\n:::\n\nIn order for the remainder of this demo to work, you will need to have\ndone 3 things:\n\n1.  Copied the [source\\_scripts]{.title-ref} folder (linked above) to\n    your working directory\n2.  Authenticated with AWS locally\n3.  Granted yourself the appropriate permissions as described in this\n    [AWS Braket setup\n    document](https://docs.aws.amazon.com/braket/latest/developerguide/braket-enable-overview.html)\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braket.aws import AwsSession, AwsQuantumJob\nfrom braket.jobs.config import InstanceConfig\nfrom braket.jobs.image_uris import Framework, retrieve_image\nimport boto3\n\nregion_name = AwsSession().region\nimage_uri = retrieve_image(Framework.BASE, region_name)\n\nn_qubits = 11\n\nhyperparameters = {\n    \"n_qubits\": n_qubits,\n    \"n_layers\": 4,\n    \"shots\": 8192,\n    \"max_iter\": 600,\n    \"learn_rate\": 1e-2,\n    \"spsa_repeats\": 25,\n}\n\njob_name = f\"ref-paper-benchmark-qubit-{n_qubits}\"\ninstance_config = InstanceConfig(instanceType=\"ml.m5.large\", volumeSizeInGb=30, instanceCount=1)\n\njob = AwsQuantumJob.create(\n    device=\"local:pennylane/lightning.qubit\",\n    source_module=\"source_scripts\",\n    entry_point=\"source_scripts.benchmark_ref_paper_converge_speed\",\n    job_name=job_name,\n    hyperparameters=hyperparameters,\n    instance_config=instance_config,\n    image_uri=image_uri,\n    wait_until_complete=False,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizing the job results, we get the following plot. The results are\nwell aligned with the observations from Gacon et al.[^1]. The stepwise\noptimization times for GD, QNG, SPSA and QN-SPSA are measured to be\n0.43s, 0.75s, 0.03s and 0.20s. In this example, the average behavior of\nSPSA matches the one from GD. QNG performs the best among the 4\ncandidates, but it requires the most circuit executions and shots per\nstep. In particular, for QPUs, this is a severe disadvantage of this\nmethod. From the more shot-frugal options, QN-SPSA demonstrates the\nfastest convergence and best final accuracy, making it a promising\ncandidate for variational algorithms.\n\n![](../demonstrations/qnspsa/qnspsa_braket.png){.align-center\nwidth=\"80.0%\"}\n\nTo sum up, in this tutorial, we showed step-by-step how we can implement\nthe QN-SPSA optimizer with PennyLane, along with a few tricks to further\nimprove the optimizer's performance. We also demonstrated how one can\nscale up the benchmarking experiments with Amazon Braket Hybrid Jobs.\n\nReferences\n==========\n\nAbout the author\n================\n\n[^1]: Gacon, J., Zoufal, C., Carleo, G., & Woerner, S. (2021).\n    *Simultaneous perturbation stochastic approximation of the quantum\n    fisher information*. [Quantum, 5,\n    567](https://quantum-journal.org/papers/q-2021-10-20-567/).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}