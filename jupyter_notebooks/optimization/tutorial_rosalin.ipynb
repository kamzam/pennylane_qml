{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Frugal shot optimization with Rosalin\n=====================================\n\n::: {.meta}\n:property=\\\"og:description\\\": The Rosalin optimizer uses a\nmeasurement-frugal optimization strategy to minimize the number of times\na quantum computer is accessed. :property=\\\"og:image\\\":\n<https://pennylane.ai/qml/_images/sphx_glr_tutorial_rosalin_002.png>\n:::\n\n::: {.related}\ntutorial\\_vqe A brief overview of VQE\ntutorial\\_quantum\\_natural\\_gradient Quantum natural gradient\ntutorial\\_doubly\\_stochastic Doubly stochastic gradient descent\ntutorial\\_rotoselect Quantum circuit structure learning\n:::\n\n*Author: Josh Izaac --- Posted: 19 May 2020. Last updated: 30 January\n2023.*\n\nIn this tutorial we investigate and implement the Rosalin (Random\nOperator Sampling for Adaptive Learning with Individual Number of shots)\nfrom Arrasmith et al.. In this paper, a strategy is introduced for\nreducing the number of shots required when optimizing variational\nquantum algorithms, by both:\n\n-   Frugally adapting the number of shots used per parameter update, and\n-   Performing a weighted sampling of operators from the cost\n    Hamiltonian.\n\n::: {.note}\n::: {.title}\nNote\n:::\n\nThe Rosalin optimizer is available in PennyLane via the\n`~.pennylane.ShotAdaptiveOptimizer`{.interpreted-text role=\"class\"}.\n:::\n\nBackground\n----------\n\nWhile a large number of papers in variational quantum algorithms focus\non the choice of circuit ansatz, cost function, gradient computation, or\ninitialization method, the optimization strategy\\-\\--an important\ncomponent affecting both convergence time and quantum resource\ndependence\\-\\--is not as frequently considered. Instead, common\n\\'out-of-the-box\\' classical optimization techniques, such as\ngradient-free methods (COBLYA, Nelder-Mead), gradient-descent, and\nHessian-free methods (L-BFGS) tend to be used.\n\nHowever, for variational algorithms such as\n`VQE </demos/tutorial_vqe>`{.interpreted-text role=\"doc\"}, which involve\nevaluating a large number of non-commuting operators in the cost\nfunction, decreasing the number of quantum evaluations required for\nconvergence, while still minimizing statistical noise, can be a delicate\nbalance.\n\nRecent work has highlighted that \\'quantum-aware\\' optimization\ntechniques can lead to marked improvements when training variational\nquantum algorithms:\n\n-   `/demos/tutorial_quantum_natural_gradient`{.interpreted-text\n    role=\"doc\"} descent by Stokes et al., which takes into account the\n    quantum geometry during the gradient-descent update step.\n-   The work of Sweke et al., which shows that quantum gradient descent\n    with a finite number of shots is equivalent to [stochastic gradient\n    descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent),\n    and has guaranteed convergence. Furthermore, combining a finite\n    number of shots with weighted sampling of the cost function terms\n    leads to `/demos/tutorial_doubly_stochastic`{.interpreted-text\n    role=\"doc\"}.\n-   The iCANS (individual Coupled Adaptive Number of Shots) optimization\n    technique by Jonas Kuebler et al. adapts the number of shots\n    measurements during training, by maximizing the expected gain per\n    shot.\n\nIn this latest result by Arrasmith et al., the idea of doubly stochastic\ngradient descent has been used to extend the iCANS optimizer, resulting\nin faster convergence.\n\nOver the course of this tutorial, we will explore their results;\nbeginning first with a demonstration of *weighted random sampling* of\nthe cost Hamiltonian operators, before combining this with the\nshot-frugal iCANS optimizer to perform doubly stochastic Rosalin\noptimization.\n\nWeighted random sampling\n------------------------\n\nConsider a Hamiltonian $H$ expanded as a weighted sum of operators $h_i$\nthat can be directly measured:\n\n$$H = \\sum_{i=1}^N c_i h_i.$$\n\nDue to the linearity of expectation values, the expectation value of\nthis Hamiltonian can be expressed as the weighted sum of each individual\nterm:\n\n$$\\langle H\\rangle = \\sum_{i=1}^N c_i \\langle h_i\\rangle.$$\n\nIn the\n`doubly stochastic gradient descent demonstration </demos/tutorial_doubly_stochastic>`{.interpreted-text\nrole=\"doc\"}, we estimated this expectation value by **uniformly\nsampling** a subset of the terms at each optimization step, and\nevaluating each term by using the same finite number of shots $N$.\n\nHowever, what happens if we use a weighted approach to determine how to\ndistribute our samples across the terms of the Hamiltonian? In\n**weighted random sampling** (WRS), the number of shots used to\ndetermine the expectation value $\\langle h_i\\rangle$ is a discrete\nrandom variable distributed according to a [multinomial\ndistribution](https://en.wikipedia.org/wiki/Multinomial_distribution),\n\n$$S \\sim \\text{Multinomial}(p_i),$$\n\nwith event probabilities\n\n$$p_i = \\frac{|c_i|}{\\sum_i |c_i|}.$$\n\nThat is, the number of shots assigned to the measurement of the\nexpectation value of the $i\\text{th}$ term of the Hamiltonian is drawn\nfrom a probability distribution *proportional to the magnitude of its\ncoefficient* $c_i$.\n\nTo see this strategy in action, consider the Hamiltonian\n\n$$H = 2I\\otimes X + 4 I\\otimes Z  - X\\otimes X + 5Y\\otimes Y + 2 Z\\otimes X.$$\n\nWe can solve for the ground state energy using the variational quantum\neigensolver (VQE) algorithm.\n\nFirst, let\\'s import NumPy and PennyLane, and define our Hamiltonian.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\nfrom pennylane import numpy as np\n\n# set the random seed\nnp.random.seed(4)\n\ncoeffs = [2, 4, -1, 5, 2]\n\nobs = [\n  qml.PauliX(1),\n  qml.PauliZ(1),\n  qml.PauliX(0) @ qml.PauliX(1),\n  qml.PauliY(0) @ qml.PauliY(1),\n  qml.PauliZ(0) @ qml.PauliZ(1)\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now create our quantum device (let\\'s use the `default.qubit`\nsimulator).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_layers = 2\nnum_wires = 2\n\n# create a device that estimates expectation values using a finite number of shots\nnon_analytic_dev = qml.device(\"default.qubit\", wires=num_wires, shots=100)\n\n# create a device that calculates exact expectation values\nanalytic_dev = qml.device(\"default.qubit\", wires=num_wires, shots=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let\\'s set the total number of shots, and determine the probability\nfor sampling each Hamiltonian term.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "total_shots = 8000\nprob_shots = np.abs(coeffs) / np.sum(np.abs(coeffs))\nprint(prob_shots)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now use SciPy to create our multinomial distributed random\nvariable $S$, using the number of trials (total shot number) and\nprobability values:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.stats import multinomial\n\nsi = multinomial(n=total_shots, p=prob_shots)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sampling from this distribution will provide the number of shots used to\nsample each term in the Hamiltonian:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "samples = si.rvs()[0]\nprint(samples)\nprint(sum(samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, if we sum the sampled shots per term, we recover the total\nnumber of shots.\n\nLet\\'s now create our cost function. Recall that the cost function must\ndo the following:\n\n1.  It must sample from the multinomial distribution we created above,\n    to determine the number of shots $s_i$ to use to estimate the\n    expectation value of the ith Hamiltonian term.\n2.  It then must estimate the expectation value $\\langle h_i\\rangle$ by\n    creating the required QNode. For our ansatz, we\\'ll use the\n    `~.pennylane.templates.layers.StronglyEntanglingLayers`{.interpreted-text\n    role=\"class\"}.\n3.  And, last but not least, estimate the expectation value\n    $\\langle H\\rangle = \\sum_i c_i\\langle h_i\\rangle$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pennylane.templates.layers import StronglyEntanglingLayers\n\n\n@qml.qnode(non_analytic_dev, diff_method=\"parameter-shift\", interface=\"autograd\")\ndef qnode(weights, observable):\n    StronglyEntanglingLayers(weights, wires=non_analytic_dev.wires)\n    return qml.expval(observable)\n\ndef cost(params):\n    # sample from the multinomial distribution\n    shots_per_term = si.rvs()[0]\n\n    result = 0\n\n    for o, c, s in zip(obs, coeffs, shots_per_term):\n        # evaluate the QNode corresponding to\n        # the Hamiltonian term, and add it on to our running sum\n        result += c * qnode(params, o, shots=int(s))\n\n    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluating our cost function with some initial parameters, we can test\nout that our cost function evaluates correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "param_shape = StronglyEntanglingLayers.shape(n_layers=num_layers, n_wires=num_wires)\ninit_params = np.random.uniform(low=0.0, high=2*np.pi, size=param_shape, requires_grad=True)\nprint(cost(init_params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Performing the optimization, with the number of shots randomly\ndetermined at each optimization step:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "opt = qml.AdamOptimizer(0.05)\nparams = init_params\n\ncost_wrs = []\nshots_wrs = []\n\nfor i in range(100):\n    params, _cost = opt.step_and_cost(cost, params)\n    cost_wrs.append(_cost)\n    shots_wrs.append(total_shots*i)\n    print(\"Step {}: cost = {} shots used = {}\".format(i, cost_wrs[-1], shots_wrs[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\\'s compare this against an optimization not using weighted random\nsampling. Here, we will split the 8000 total shots evenly across all\nHamiltonian terms, also known as *uniform deterministic sampling*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@qml.qnode(non_analytic_dev, diff_method=\"parameter-shift\", interface=\"autograd\")\ndef qnode(weights, obs):\n    StronglyEntanglingLayers(weights, wires=non_analytic_dev.wires)\n    return qml.expval(obs)\n\ndef cost(params):\n    shots_per_term = int(total_shots / len(coeffs))\n\n    result = 0\n\n    for o, c in zip(obs, coeffs):\n\n        # evaluate the QNode corresponding to\n        # the Hamiltonian term, and add it on to our running sum\n        result += c * qnode(params, o, shots=shots_per_term)\n\n    return result\n\nopt = qml.AdamOptimizer(0.05)\nparams = init_params\n\ncost_adam = []\nshots_adam = []\n\nfor i in range(100):\n    params, _cost = opt.step_and_cost(cost, params)\n    cost_adam.append(_cost)\n    shots_adam.append(total_shots*i)\n    print(\"Step {}: cost = {} shots used = {}\".format(i, cost_adam[-1], shots_adam[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparing these two techniques:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n\nplt.style.use(\"seaborn\")\nplt.plot(shots_wrs, cost_wrs, \"b\", label=\"Adam WRS\")\nplt.plot(shots_adam, cost_adam, \"g\", label=\"Adam\")\n\nplt.ylabel(\"Cost function value\")\nplt.xlabel(\"Number of shots\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that weighted random sampling performs just as well as the\nuniform deterministic sampling. However, weighted random sampling begins\nto show a non-negligible improvement over deterministic sampling for\nlarge Hamiltonians with highly non-uniform coefficients. For example,\nsee Fig (3) and (4) of Arrasmith et al., comparing weighted random\nsampling VQE optimization for both $\\text{H}_2$ and $\\text{LiH}$\nmolecules.\n\n::: {.note}\n::: {.title}\nNote\n:::\n\nWhile not covered here, another approach that could be taken is\n*weighted deterministic sampling*. Here, the number of shots is\ndistributed across terms as per\n\n$$s_i = \\left\\lfloor N \\frac{|c_i|}{\\sum_i |c_i|}\\right\\rfloor,$$\n\nwhere $N$ is the total number of shots.\n:::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rosalin: Frugal shot optimization\n=================================\n\nWe can see above that both methods optimize fairly well; weighted random\nsampling converges just as well as evenly distributing the shots across\nall Hamiltonian terms. However, deterministic shot distribution\napproaches will always have a minimum shot value required per\nexpectation value, as below this threshold they become biased\nestimators. This is not the case with random sampling; as we saw in the\n`doubly stochastic gradient descent demonstration </demos/tutorial_doubly_stochastic>`{.interpreted-text\nrole=\"doc\"}, the introduction of randomness allows for as little as a\nsingle shot per expectation term, while still remaining an unbiased\nestimator.\n\nUsing this insight, Arrasmith et al. modified the iCANS frugal\nshot-optimization technique to include weighted random sampling, making\nit \\'doubly stochastic\\'.\n\niCANS optimizer\n---------------\n\nTwo variants of the iCANS optimizer were introduced in K\u00fcbler et al.,\niCANS1 and iCANS2. The iCANS1 optimizer, on which Rosalin is based,\nfrugally distributes a shot budget across the partial derivatives of\neach parameter, which are computed using the\n`parameter-shift rule </glossary/quantum_gradient>`{.interpreted-text\nrole=\"doc\"}. It works roughly as follows:\n\n1.  The initial step of the optimizer is performed with some specified\n    minimum number of shots, $s_{min}$, for all partial derivatives.\n\n2.  The parameter-shift rule is then used to estimate the gradient $g_i$\n    for each parameter $\\theta_i$, parameters, as well as the\n    *variances* $v_i$ of the estimated gradients.\n\n3.  Gradient descent is performed for each parameter $\\theta_i$, using\n    the pre-defined learning rate $\\alpha$ and the gradient information\n    $g_i$:\n\n    $$\\theta_i = \\theta_i - \\alpha g_i.$$\n\n4.  The improvement in the cost function per shot, for a specific\n    parameter value, is then calculated via\n\n    $$\\gamma_i = \\frac{1}{s_i} \\left[ \\left(\\alpha - \\frac{1}{2} L\\alpha^2\\right)\n                g_i^2 - \\frac{L\\alpha^2}{2s_i}v_i \\right],$$\n\n    where:\n\n    -   $L \\leq \\sum_i|c_i|$ is the bound on the [Lipschitz\n        constant](https://en.wikipedia.org/wiki/Lipschitz_continuity) of\n        the variational quantum algorithm objective function,\n    -   $c_i$ are the coefficients of the Hamiltonian, and\n    -   $\\alpha$ is the learning rate, and *must* be bound such that\n        $\\alpha < 2/L$ for the above expression to hold.\n\n5.  Finally, the new values of $s_i$ (shots for partial derivative of\n    parameter $\\theta_i$) is given by:\n\n    $$s_i = \\frac{2L\\alpha}{2-L\\alpha}\\left(\\frac{v_i}{g_i^2}\\right)\\propto\n          \\frac{v_i}{g_i^2}.$$\n\nIn addition to the above, to counteract the presence of noise in the\nsystem, a running average of $g_i$ and $s_i$ ($\\chi_i$ and $\\xi_i$\nrespectively) are used when computing $\\gamma_i$ and $s_i$.\n\n::: {.note}\n::: {.title}\nNote\n:::\n\nIn classical machine learning, the Lipschitz constant of the cost\nfunction is generally unknown. However, for a variational quantum\nalgorithm with cost of the form\n$f(x) = \\langle \\psi(x) | \\hat{H} |\\psi(x)\\rangle$, an upper bound on\nthe Lipschitz constant is given by $L < \\sum_i|c_i|$, where $c_i$ are\nthe coefficients of $\\hat{H}$ when decomposed into a linear combination\nof Pauli-operator tensor products.\n:::\n\nRosalin implementation\n----------------------\n\nLet\\'s now modify iCANS above to incorporate weighted random sampling of\nHamiltonian terms \\-\\-- the Rosalin frugal shot optimizer.\n\nRosalin takes several hyper-parameters:\n\n-   `min_shots`: the minimum number of shots used to estimate the\n    expectations of each term in the Hamiltonian. Note that this must be\n    larger than 2 for the variance of the gradients to be computed.\n-   `mu`: The running average constant $\\mu\\in[0, 1]$. Used to control\n    how quickly the number of shots recommended for each gradient\n    component changes.\n-   `b`: Regularization bias. The bias should be kept small, but\n    non-zero.\n-   `lr`: The learning rate. Recall from above that the learning rate\n    *must* be such that $\\alpha < 2/L = 2/\\sum_i|c_i|$.\n\nSince the Rosalin optimizer has a state that must be preserved between\noptimization steps, let\\'s use a class to create our optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Rosalin:\n\n    def __init__(self, obs, coeffs, min_shots, mu=0.99, b=1e-6, lr=0.07):\n        self.obs = obs\n        self.coeffs = coeffs\n\n        self.lipschitz = np.sum(np.abs(coeffs))\n\n        if lr > 2 / self.lipschitz:\n            raise ValueError(\"The learning rate must be less than \", 2 / self.lipschitz)\n\n        # hyperparameters\n        self.min_shots = min_shots\n        self.mu = mu  # running average constant\n        self.b = b    # regularization bias\n        self.lr = lr  # learning rate\n\n        # keep track of the total number of shots used\n        self.shots_used = 0\n        # total number of iterations\n        self.k = 0\n        # Number of shots per parameter\n        self.s = np.zeros_like(params, dtype=np.float64) + min_shots\n\n        # Running average of the parameter gradients\n        self.chi = None\n        # Running average of the variance of the parameter gradients\n        self.xi = None\n\n    def estimate_hamiltonian(self, params, shots):\n        \"\"\"Returns an array containing length ``shots`` single-shot estimates\n        of the Hamiltonian. The shots are distributed randomly over\n        the terms in the Hamiltonian, as per a Multinomial distribution.\n\n        Since we are performing single-shot estimates, the QNodes must be\n        set to 'sample' mode.\n        \"\"\"\n        rosalin_device = qml.device(\"default.qubit\", wires=num_wires, shots=100)\n\n        # determine the shot probability per term\n        prob_shots = np.abs(coeffs) / np.sum(np.abs(coeffs))\n\n        # construct the multinomial distribution, and sample\n        # from it to determine how many shots to apply per term\n        si = multinomial(n=shots, p=prob_shots)\n        shots_per_term = si.rvs()[0]\n\n        results = []\n\n        @qml.qnode(rosalin_device, diff_method=\"parameter-shift\", interface=\"autograd\")\n        def qnode(weights, observable):\n            StronglyEntanglingLayers(weights, wires=rosalin_device.wires)\n            return qml.sample(observable)\n\n        for o, c, p, s in zip(self.obs, self.coeffs, prob_shots, shots_per_term):\n\n            # if the number of shots is 0, do nothing\n            if s == 0:\n                continue\n\n            # evaluate the QNode corresponding to\n            # the Hamiltonian term\n            res = qnode(params, o, shots=int(s))\n\n            if s == 1:\n                res = np.array([res])\n\n            # Note that, unlike above, we divide each term by the\n            # probability per shot. This is because we are sampling one at a time.\n            results.append(c * res / p)\n\n        return np.concatenate(results)\n\n    def evaluate_grad_var(self, i, params, shots):\n        \"\"\"Evaluate the gradient, as well as the variance in the gradient,\n        for the ith parameter in params, using the parameter-shift rule.\n        \"\"\"\n        shift = np.zeros_like(params)\n        shift[i] = np.pi / 2\n\n        shift_forward = self.estimate_hamiltonian(params + shift, shots)\n        shift_backward = self.estimate_hamiltonian(params - shift, shots)\n\n        g = np.mean(shift_forward - shift_backward) / 2\n        s = np.var((shift_forward - shift_backward) / 2, ddof=1)\n\n        return g, s\n\n    def step(self, params):\n        \"\"\"Perform a single step of the Rosalin optimizer.\"\"\"\n        # keep track of the number of shots run\n        self.shots_used += int(2 * np.sum(self.s))\n\n        # compute the gradient, as well as the variance in the gradient,\n        # using the number of shots determined by the array s.\n        grad = []\n        S = []\n\n        p_ind = list(np.ndindex(*params.shape))\n\n        for l in p_ind:\n            # loop through each parameter, performing\n            # the parameter-shift rule\n            g_, s_ = self.evaluate_grad_var(l, params, self.s[l])\n            grad.append(g_)\n            S.append(s_)\n\n        grad = np.reshape(np.stack(grad), params.shape)\n        S = np.reshape(np.stack(S), params.shape)\n\n        # gradient descent update\n        params = params - self.lr * grad\n\n        if self.xi is None:\n            self.chi = np.zeros_like(params, dtype=np.float64)\n            self.xi = np.zeros_like(params, dtype=np.float64)\n\n        # running average of the gradient variance\n        self.xi = self.mu * self.xi + (1 - self.mu) * S\n        xi = self.xi / (1 - self.mu ** (self.k + 1))\n\n        # running average of the gradient\n        self.chi = self.mu * self.chi + (1 - self.mu) * grad\n        chi = self.chi / (1 - self.mu ** (self.k + 1))\n\n        # determine the new optimum shots distribution for the next\n        # iteration of the optimizer\n        s = np.ceil(\n            (2 * self.lipschitz * self.lr * xi)\n            / ((2 - self.lipschitz * self.lr) * (chi ** 2 + self.b * (self.mu ** self.k)))\n        )\n\n        # apply an upper and lower bound on the new shot distributions,\n        # to avoid the number of shots reducing below min(2, min_shots),\n        # or growing too significantly.\n        gamma = (\n            (self.lr - self.lipschitz * self.lr ** 2 / 2) * chi ** 2\n            - xi * self.lipschitz * self.lr ** 2 / (2 * s)\n        ) / s\n\n        argmax_gamma = np.unravel_index(np.argmax(gamma), gamma.shape)\n        smax = s[argmax_gamma]\n        self.s = np.clip(s, min(2, self.min_shots), smax)\n\n        self.k += 1\n        return params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rosalin optimization\n====================\n\nWe are now ready to use our Rosalin optimizer to optimize the initial\nVQE problem. But first let\\'s also create a separate cost function using\nan \\'exact\\' quantum device, so that we can keep track of the *exact*\ncost function value at each iteration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@qml.qnode(analytic_dev, interface=\"autograd\")\ndef cost_analytic(weights):\n    StronglyEntanglingLayers(weights, wires=analytic_dev.wires)\n    return qml.expval(qml.Hamiltonian(coeffs, obs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating the optimizer and beginning the optimization:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "opt = Rosalin(obs, coeffs, min_shots=10)\nparams = init_params\n\ncost_rosalin = [cost_analytic(params)]\nshots_rosalin = [0]\n\nfor i in range(60):\n    params = opt.step(params)\n    cost_rosalin.append(cost_analytic(params))\n    shots_rosalin.append(opt.shots_used)\n    print(f\"Step {i}: cost = {cost_rosalin[-1]}, shots_used = {shots_rosalin[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\\'s compare this to a standard Adam optimization. Using 100 shots per\nquantum evaluation, for each update step there are 2 quantum evaluations\nper parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adam_shots_per_eval = 100\nadam_shots_per_step = 2 * adam_shots_per_eval * len(params.flatten())\nprint(adam_shots_per_step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus, Adam is using 2400 shots per update step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = init_params\nopt = qml.AdamOptimizer(0.07)\n\nnon_analytic_dev.shots = adam_shots_per_eval\n\n@qml.qnode(non_analytic_dev, diff_method=\"parameter-shift\", interface=\"autograd\")\ndef cost(weights):\n    StronglyEntanglingLayers(weights, wires=non_analytic_dev.wires)\n    return qml.expval(qml.Hamiltonian(coeffs, obs))\n\ncost_adam = [cost_analytic(params)]\nshots_adam = [0]\n\nfor i in range(100):\n    params = opt.step(cost, params)\n    cost_adam.append(cost_analytic(params))\n    shots_adam.append(adam_shots_per_step * (i + 1))\n    print(\"Step {}: cost = {} shots_used = {}\".format(i, cost_adam[-1], shots_adam[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting both experiments:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.style.use(\"seaborn\")\nplt.plot(shots_rosalin, cost_rosalin, \"b\", label=\"Rosalin\")\nplt.plot(shots_adam, cost_adam, \"g\", label=\"Adam\")\n\nplt.ylabel(\"Cost function value\")\nplt.xlabel(\"Number of shots\")\nplt.legend()\nplt.xlim(0, 300000)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Rosalin optimizer performs significantly better than the Adam\noptimizer, approaching the ground state energy of the Hamiltonian with\nstrikingly fewer shots.\n\nWhile beyond the scope of this demonstration, the Rosalin optimizer can\nbe modified in various other ways; for instance, by incorporating\n*weighted hybrid sampling* (which distributes some shots\ndeterministically, with the remainder done randomly), or by adapting the\nvariant iCANS2 optimizer. Download this demonstration from the sidebar \ud83d\udc49\nand give it a go! \u269b\ufe0f\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n==========\n\nAbout the author\n================\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}