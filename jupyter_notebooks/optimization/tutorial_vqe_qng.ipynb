{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accelerating VQEs with quantum natural gradient\n===============================================\n\n::: {.meta}\n:property=\\\"og:description\\\": Accelerating variational quantum\neigensolvers using quantum natural gradients in PennyLane.\n:property=\\\"og:image\\\":\n<https://pennylane.ai/qml/_images/qng_example.png>\n:::\n\n::: {.related}\ntutorial\\_vqe A brief overview of VQE\ntutorial\\_quantum\\_natural\\_gradient Quantum natural gradient\n:::\n\n*Authors: Maggie Li, Lana Bozanic, Sukin Sim --- Posted: 06 November\n2020. Last updated: 08 April 2021.*\n\nThis tutorial showcases how one can apply quantum natural gradients\n(QNG) to accelerate the optimization step of the Variational Quantum\nEigensolver (VQE) algorithm. We will implement two small examples:\nestimating the ground state energy of a single-qubit VQE problem, which\nwe can visualize using the Bloch sphere, and the hydrogen molecule.\n\nBefore going through this tutorial, we recommend that readers refer to\nthe\n`QNG tutorial </demos/tutorial_quantum_natural_gradient>`{.interpreted-text\nrole=\"doc\"} and `VQE tutorial </demos/tutorial_vqe>`{.interpreted-text\nrole=\"doc\"} for overviews of quantum natural gradient and the\nvariational quantum eigensolver algorithm, respectively. Let\\'s get\nstarted!\n\nSingle-qubit VQE example\n------------------------\n\nThe first step is to import the required libraries and packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom pennylane import numpy as np\nimport pennylane as qml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this simple example, we consider the following single-qubit\nHamiltonian: $\\sigma_x + \\sigma_z$.\n\nWe define the device:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"default.qubit\", wires=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the variational ansatz, we use two single-qubit rotations, which the\nuser may recognize from a previous\n`tutorial </demos/tutorial_qubit_rotation>`{.interpreted-text\nrole=\"doc\"} on qubit rotations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def circuit(params, wires=0):\n    qml.RX(params[0], wires=wires)\n    qml.RY(params[1], wires=wires)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then define our cost function which supports the computation of\nblock-diagonal or diagonal approximations to the Fubini-Study metric\ntensor. This tensor is a crucial component for optimizing with quantum\nnatural gradients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coeffs = [1, 1]\nobs = [qml.PauliX(0), qml.PauliZ(0)]\n\nH = qml.Hamiltonian(coeffs, obs)\n\n@qml.qnode(dev, interface=\"autograd\")\ndef cost_fn(params):\n    circuit(params)\n    return qml.expval(H)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To analyze the performance of quantum natural gradient on VQE\ncalculations, we set up and execute optimizations using the\n`GradientDescentOptimizer` (which does not utilize quantum gradients)\nand the `QNGOptimizer` that uses the block-diagonal approximation to the\nmetric tensor.\n\nTo perform a fair comparison, we fix the initial parameters for the two\noptimizers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "init_params = np.array([3.97507603, 3.00854038], requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will carry out each optimization over a maximum of 500 steps. As was\ndone in the VQE tutorial, we aim to reach a convergence tolerance of\naround $10^{-6}$. We use a step size of 0.01.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "max_iterations = 500\nconv_tol = 1e-06\nstep_size = 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we carry out the VQE optimization using the standard gradient\ndescent method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "opt = qml.GradientDescentOptimizer(stepsize=step_size)\n\nparams = init_params\n\ngd_param_history = [params]\ngd_cost_history = []\n\nfor n in range(max_iterations):\n\n    # Take step\n    params, prev_energy = opt.step_and_cost(cost_fn, params)\n    gd_param_history.append(params)\n    gd_cost_history.append(prev_energy)\n\n    energy = cost_fn(params)\n\n    # Calculate difference between new and old energies\n    conv = np.abs(energy - prev_energy)\n\n    if n % 20 == 0:\n        print(\n            \"Iteration = {:},  Energy = {:.8f} Ha,  Convergence parameter = {\"\n            \":.8f} Ha\".format(n, energy, conv)\n        )\n\n    if conv <= conv_tol:\n        break\n\nprint()\nprint(\"Final value of the energy = {:.8f} Ha\".format(energy))\nprint(\"Number of iterations = \", n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then repeat the process for the optimizer employing quantum natural\ngradients:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "opt = qml.QNGOptimizer(stepsize=step_size, approx=\"block-diag\")\n\nparams = init_params\n\nqngd_param_history = [params]\nqngd_cost_history = []\n\nfor n in range(max_iterations):\n\n    # Take step\n    params, prev_energy = opt.step_and_cost(cost_fn, params)\n    qngd_param_history.append(params)\n    qngd_cost_history.append(prev_energy)\n\n    # Compute energy\n    energy = cost_fn(params)\n\n    # Calculate difference between new and old energies\n    conv = np.abs(energy - prev_energy)\n\n    if n % 20 == 0:\n        print(\n            \"Iteration = {:},  Energy = {:.8f} Ha,  Convergence parameter = {\"\n            \":.8f} Ha\".format(n, energy, conv)\n        )\n\n    if conv <= conv_tol:\n        break\n\nprint()\nprint(\"Final value of the energy = {:.8f} Ha\".format(energy))\nprint(\"Number of iterations = \", n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizing the results\n=======================\n\nFor single-qubit examples, we can visualize the optimization process in\nseveral ways.\n\nFor example, we can track the energy history:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.style.use(\"seaborn\")\nplt.plot(gd_cost_history, \"b\", label=\"Gradient descent\")\nplt.plot(qngd_cost_history, \"g\", label=\"Quantum natural gradient descent\")\n\nplt.ylabel(\"Cost function value\")\nplt.xlabel(\"Optimization steps\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or we can visualize the optimization path in the parameter space using a\ncontour plot. Energies at different grid points have been pre-computed,\nand they can be downloaded by clicking\n`here<../demonstrations/vqe_qng/param_landscape.npy>`{.interpreted-text\nrole=\"download\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Discretize the parameter space\ntheta0 = np.linspace(0.0, 2.0 * np.pi, 100)\ntheta1 = np.linspace(0.0, 2.0 * np.pi, 100)\n\n# Load energy value at each point in parameter space\nparameter_landscape = np.load(\"vqe_qng/param_landscape.npy\")\n\n# Plot energy landscape\nfig, axes = plt.subplots(figsize=(6, 6))\ncmap = plt.cm.get_cmap(\"coolwarm\")\ncontour_plot = plt.contourf(theta0, theta1, parameter_landscape, cmap=cmap)\nplt.xlabel(r\"$\\theta_0$\")\nplt.ylabel(r\"$\\theta_1$\")\n\n# Plot optimization path for gradient descent. Plot every 10th point.\ngd_color = \"g\"\nplt.plot(\n    np.array(gd_param_history)[::10, 0],\n    np.array(gd_param_history)[::10, 1],\n    \".\",\n    color=gd_color,\n    linewidth=1,\n    label=\"Gradient descent\",\n)\nplt.plot(\n    np.array(gd_param_history)[:, 0],\n    np.array(gd_param_history)[:, 1],\n    \"-\",\n    color=gd_color,\n    linewidth=1,\n)\n\n# Plot optimization path for quantum natural gradient descent. Plot every 10th point.\nqngd_color = \"k\"\nplt.plot(\n    np.array(qngd_param_history)[::10, 0],\n    np.array(qngd_param_history)[::10, 1],\n    \".\",\n    color=qngd_color,\n    linewidth=1,\n    label=\"Quantum natural gradient descent\",\n)\nplt.plot(\n    np.array(qngd_param_history)[:, 0],\n    np.array(qngd_param_history)[:, 1],\n    \"-\",\n    color=qngd_color,\n    linewidth=1,\n)\n\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, the blue regions indicate states with lower energies, and the red\nregions indicate states with higher energies. We can see that the\n`QNGOptimizer` takes a more direct route to the minimum in larger\nstrides compared to the path taken by the `GradientDescentOptimizer`.\n\nLastly, we can visualize the same optimization paths on the Bloch sphere\nusing routines from [QuTiP](http://qutip.org/). The result should look\nlike the following:\n\n![](/demonstrations/vqe_qng/opt_paths_bloch.png){.align-center\nwidth=\"50.0%\"}\n\nwhere again the black markers and line indicate the path taken by the\n`QNGOptimizer`, and the green markers and line indicate the path taken\nby the `GradientDescentOptimizer`. Using this visualization method, we\ncan clearly see how the path using the `QNGOptimizer` tightly \\\"hugs\\\"\nthe curvature of the Bloch sphere and takes the shorter path.\n\nNow, we will move onto a more interesting example: estimating the ground\nstate energy of molecular hydrogen.\n\nHydrogen VQE Example\n====================\n\nTo construct our system Hamiltonian, we first read the molecular\ngeometry from the external file\n`h2.xyz </demonstrations/h2.xyz>`{.interpreted-text role=\"download\"}\nusing the `~.pennylane.qchem.read_structure`{.interpreted-text\nrole=\"func\"} function (see more details in the\n`tutorial_quantum_chemistry`{.interpreted-text role=\"doc\"} tutorial).\nThe molecular Hamiltonian is then built using the\n`~.pennylane.qchem.molecular_hamiltonian`{.interpreted-text role=\"func\"}\nfunction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_file = \"h2.xyz\"\n\nsymbols, coordinates = qml.qchem.read_structure(geo_file)\nhamiltonian, qubits = qml.qchem.molecular_hamiltonian(symbols, coordinates)\n\nprint(\"Number of qubits = \", qubits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For our ansatz, we use the circuit from the [VQE\ntutorial](https://pennylane.ai/qml/demos/tutorial_vqe.html) but expand\nout the arbitrary single-qubit rotations to elementary gates (RZ-RY-RZ).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"default.qubit\", wires=qubits)\nhf_state = np.array([1, 1, 0, 0], requires_grad=False)\n\ndef ansatz(params, wires=[0, 1, 2, 3]):\n    qml.BasisState(hf_state, wires=wires)\n    for i in wires:\n        qml.RZ(params[3 * i], wires=i)\n        qml.RY(params[3 * i + 1], wires=i)\n        qml.RZ(params[3 * i + 2], wires=i)\n    qml.CNOT(wires=[2, 3])\n    qml.CNOT(wires=[2, 0])\n    qml.CNOT(wires=[3, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the qubit register has been initialized to $|1100\\rangle$,\nwhich encodes for the Hartree-Fock state of the hydrogen molecule\ndescribed in the minimal basis. Again, we define the cost function to be\nthe following QNode that measures `expval(H)`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev, interface=\"autograd\")\ndef cost(params):\n    ansatz(params)\n    return qml.expval(hamiltonian)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this problem, we can compute the exact value of the ground state\nenergy via exact diagonalization. We provide the value below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exact_value = -1.136189454088"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now set up our optimizations runs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\ninit_params = np.random.uniform(low=0, high=2 * np.pi, size=12, requires_grad=True)\nmax_iterations = 500\nstep_size = 0.5\nconv_tol = 1e-06"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As was done with our previous VQE example, we run the standard gradient\ndescent optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "opt = qml.GradientDescentOptimizer(step_size)\n\nparams = init_params\n\ngd_cost = []\n\nfor n in range(max_iterations):\n    params, prev_energy = opt.step_and_cost(cost, params)\n    gd_cost.append(prev_energy)\n\n    energy = cost(params)\n    conv = np.abs(energy - prev_energy)\n\n    if n % 20 == 0:\n        print(\n            \"Iteration = {:},  Energy = {:.8f} Ha\".format(n, energy)\n        )\n\n    if conv <= conv_tol:\n        break\n\n\nprint()\nprint(\"Final convergence parameter = {:.8f} Ha\".format(conv))\nprint(\"Number of iterations = \", n)\nprint(\"Final value of the ground-state energy = {:.8f} Ha\".format(energy))\nprint(\n    \"Accuracy with respect to the FCI energy: {:.8f} Ha ({:.8f} kcal/mol)\".format(\n        np.abs(energy - exact_value), np.abs(energy - exact_value) * 627.503\n    )\n)\nprint()\nprint(\"Final circuit parameters = \\n\", params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we run the optimizer employing quantum natural gradients. We also\nneed to make the Hamiltonian coefficients non-differentiable by setting\n`requires_grad=False`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hamiltonian = qml.Hamiltonian(np.array(hamiltonian.coeffs, requires_grad=False), hamiltonian.ops)\n\nopt = qml.QNGOptimizer(step_size, lam=0.001, approx=\"block-diag\")\n\nparams = init_params\nprev_energy = cost(params)\nqngd_cost = []\n\nfor n in range(max_iterations):\n    params, prev_energy = opt.step_and_cost(cost, params)\n    qngd_cost.append(prev_energy)\n\n    energy = cost(params)\n    conv = np.abs(energy - prev_energy)\n\n    if n % 4 == 0:\n        print(\n            \"Iteration = {:},  Energy = {:.8f} Ha\".format(n, energy)\n        )\n\n    if conv <= conv_tol:\n        break\n\n\nprint(\"\\nFinal convergence parameter = {:.8f} Ha\".format(conv))\nprint(\"Number of iterations = \", n)\nprint(\"Final value of the ground-state energy = {:.8f} Ha\".format(energy))\nprint(\n    \"Accuracy with respect to the FCI energy: {:.8f} Ha ({:.8f} kcal/mol)\".format(\n        np.abs(energy - exact_value), np.abs(energy - exact_value) * 627.503\n    )\n)\nprint()\nprint(\"Final circuit parameters = \\n\", params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizing the results\n=======================\n\nTo evaluate the performance of our two optimizers, we can compare: (a)\nthe number of steps it takes to reach our ground state estimate and (b)\nthe quality of our ground state estimate by comparing the final\noptimization energy to the exact value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.style.use(\"seaborn\")\nplt.plot(np.array(gd_cost) - exact_value, \"g\", label=\"Gradient descent\")\nplt.plot(np.array(qngd_cost) - exact_value, \"k\", label=\"Quantum natural gradient descent\")\nplt.yscale(\"log\")\nplt.ylabel(\"Energy difference\")\nplt.xlabel(\"Step\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that by employing quantum natural gradients, it takes fewer steps\nto reach a ground state estimate and the optimized energy achieved by\nthe optimizer is lower than that obtained using vanilla gradient\ndescent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Robustness in parameter initialization\n======================================\n\nWhile results above show a more rapid convergence for quantum natural\ngradients, what if we were just lucky, i.e., we started at a \\\"good\\\"\npoint in parameter space? How do we know this will be the case with high\nprobability regardless of the parameter initialization?\n\nUsing the same system Hamiltonian, ansatz, and device, we tested the\nrobustness of the `QNGOptimizer` by running 10 independent trials with\nrandom parameter initializations. For this numerical test, our optimizer\ndoes not terminate based on energy improvement; we fix the number of\niterations to 200. We show the result of this test below (after\npre-computing), where we plot the mean and standard deviation of the\nenergies over optimization steps for quantum natural gradient and\nstandard gradient descent.\n\n![](../demonstrations/vqe_qng/k_runs_.png){.align-center width=\"60.0%\"}\n\nWe observe that quantum natural gradient on average converges faster for\nthis system.\n\n::: {.note}\n::: {.title}\nNote\n:::\n\nWhile using QNG may help accelerate the VQE algorithm in terms of\noptimization steps, each QNG step is more costly than its vanilla\ngradient descent counterpart due to a greater number of calls to the\nquantum computer that are needed to compute the Fubini-Study metric\ntensor.\n:::\n\nWhile further benchmark studies are needed to better understand the\nadvantages of quantum natural gradient, preliminary studies such as this\ntutorial show the potentials of the method. \ud83c\udf89\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n==========\n\nAbout the authors\n=================\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}