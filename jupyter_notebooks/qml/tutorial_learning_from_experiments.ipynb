{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantum advantage in learning from experiments\n==============================================\n\n::: {.meta}\n:property=\\\"og:description\\\": Learn how quantum memory can boost quantum\nmachine learning algorithms :property=\\\"og:image\\\":\n<https://pennylane.ai/qml/_images/learning_from_exp_thumbnail.png>\n:::\n\n*Author: Joseph Bowles --- Posted: 18 April 2022. Last updated: 30 June\n2022.*\n\nThis demo is based on the article [Quantum advantage in learning from\nexperiments](https://arxiv.org/abs/2112.00778) [\\[1\\]](#ref1) by\nHsin-Yuan Huang and co-authors. The article investigates the following\nquestion:\n\n*How useful is access to quantum memory for quantum machine learning?*\n\nThey show that access to quantum memory can make a big difference, and\nprove that there exist learning problems for which algorithms with\nquantum memory require *exponentially less resources* than those\nwithout. We look at one learning task studied in [\\[1\\]](#ref1) for\nwhich this is the case.\n\nThe learning task\n-----------------\n\nThe learning task we focus on involves deciding if a unitary is\ntime-reversal symmetric (we'll call them T-symmetric) or not.\nMathematically, time-reversal symmetry in quantum mechanics involves\nreversing the sense of $i$ so that $i \\rightarrow -i$. Hence, a unitary\n$U$ is T-symmetric if\n\n$$U^*=U.$$\n\nNow for the learning task. Let's say we have a bunch of quantum circuits\n$U_1, \\cdots, U_n$, some of which are T-symmetric and some not, but we\nare not told which ones are which.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../demonstrations/learning_from_experiments/fig1b.png){.align-center\nwidth=\"50.0%\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The task is to design an algorithm to determine which of the $U$'s are\nT-symmetric and which are not, given query access to the unitaries. Note\nthat we do not have any labels here, so this is an unsupervised learning\ntask. To make things concrete, let's consider unitaries acting on 8\nqubits. We will also limit the number of times we can use each unitary:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "qubits = 8  # the number of qubits on which the unitaries act\nn_shots = 100  # the number of times we can use each unitary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Experiments with and without a quantum memory\n=============================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To tackle this task we consider experiments with and without quantum\nmemory. We also assume that we have access to a single physical\nrealization of each unitary; in other words, we do not have multiple\ncopies of the devices that implement $U_i$.\n\nAn experiment without quantum memory can therefore only make use of a\nsingle query to $U_i$ in each circuit, since querying $U_i$ again would\nrequire storing the state of the first query in memory and re-using the\nunitary. In the paper these experiments are called **conventional\nexperiments**.\n\nExperiments with quantum memory do not have the limitations of\nconventional experiments. This means that multiple queries can be made\nto $U_i$ in a single circuit, which can be realized in practice by using\na quantum memory. These experiments are called **quantum-enhanced\nexperiments**.\n\nNote that we are not comparing classical and quantum algorithms here,\nbut rather two classes of quantum algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../demonstrations/learning_from_experiments/experiments.png){.align-center\nwidth=\"60.0%\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The conventional way\n====================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we will try to solve the task with a conventional experiment. Our\nstrategy will be as follows:\n\n-   For each $U_i$, we prepare `n_shots` copies of the state\n    $U_i\\vert0\\rangle$ and measure each state to generate classical\n    measurement data.\n-   Use an unsupervised classical machine learning algorithm (kernel\n    PCA), to try and separate the data into two clusters corresponding\n    to T-symmetric unitaries vs.\u00a0the rest.\n\nIf we succeed in clustering the data then we have successfully managed\nto discriminate the two classes!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../demonstrations/learning_from_experiments/fig2b.png){.align-center\nwidth=\"70.0%\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To generate the measurement data, we will measure the states\n$U_i\\vert0\\rangle$ in the $y$ basis. The local expectation values take\nthe form\n\n$$E_i  = \\langle 0\\vert U^{\\dagger}\\sigma_y^{(i)} U \\vert 0 \\rangle.$$\n\nwhere $\\sigma_y^{(i)}$ acts on the $i^{\\text{th}}$ qubit.\n\nUsing the fact that $\\sigma_y^*=-\\sigma_y$ and the property $U^*=U$ for\nT-symmetric unitaries, one finds\n\n$$E_i^*=\\langle 0\\vert (U^{\\dagger})^*(\\sigma_y^{(i)})^* (U)^* \\vert 0 \\rangle = - \\langle 0\\vert U^{\\dagger}\\sigma_y^{(i)} U \\vert 0 \\rangle = - E_i.$$\n\nSince $E_i$ is a real number, the only solution to this is $E_i=0$,\nwhich implies that all local expectations values are 0 for this class.\n\nFor general unitaries it is not the case that $E_i=0$, and so it seems\nas though this will allow us to discriminate the two classes of circuits\neasily. However, for general random unitaries the local expectation\nvalues approach zero exponentially with the number of qubits: from\nfinite measurement data it can still be very hard to see any difference!\nIn fact, in the article [exponential separations between learning with\nand without quantum memory](https://arxiv.org/abs/2111.05881)\n[\\[2\\]](#ref2) it is proven that using conventional experiments, any\nsuccessful algorithm *must* use the unitaries an exponential number of\ntimes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see how this looks in practice. First we define a function to\ngenerate random unitaries, making use of Pennylane's\n[RandomLayers](https://pennylane.readthedocs.io/en/stable/code/api/pennylane.RandomLayers.html)\ntemplate. For the time-symmetric case we will only allow for Y\nrotations, since these unitaries contain only real numbers, and\ntherefore result in T-symmetric unitaries. For the other unitaries, we\nwill allow rotations about X,Y, and Z.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\nfrom pennylane.templates.layers import RandomLayers\nfrom pennylane import numpy as np\n\nnp.random.seed(234087)\n\nlayers, gates = 10, 10  # the number of layers and gates used in RandomLayers\n\n\ndef generate_circuit(shots):\n    \"\"\"\n    generate a random circuit that returns a number of measuement samples\n    given by shots\n    \"\"\"\n    dev = qml.device(\"default.qubit\", wires=qubits, shots=shots)\n\n    @qml.qnode(dev)\n    def circuit(ts=False):\n\n        if ts == True:\n            ops = [qml.RY]  # time-symmetric unitaries\n        else:\n            ops = [qml.RX, qml.RY, qml.RZ]  # general unitaries\n\n        weights = np.random.rand(layers, gates) * np.pi\n        RandomLayers(weights, wires=range(qubits), rotations=ops, seed=np.random.randint(0, 10000))\n\n        return [qml.sample(op=qml.PauliY(q)) for q in range(qubits)]\n\n    return circuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "let's check if that worked:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# the measurement outcomes for the first 3 shots\ncircuit = generate_circuit(n_shots)\nprint(circuit(ts=True)[:, 0:3])\nprint(\"\\n\")\nprint(circuit(ts=False)[:, 0:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can generate some data. The first 30 circuits in the data set are\nT-symmetric and the second 30 circuits are not. Since we are in an\nunsupervised setting, the algorithm will not know this information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "circuits = 30  # the number of circuits in each data set\n\nraw_data = []\n\nfor ts in [True, False]:\n    for __ in range(circuits):\n        circuit = generate_circuit(n_shots)\n        raw_data.append(circuit(ts=ts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before feeding the data to a clustering algorithm, we will process it a\nlittle. For each circuit, we calculate the mean and the variance of each\noutput bit and store this in a vector of size `2*qubits`. These vectors\nmake up our classical data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def process_data(raw_data):\n    \"convert raw data to vectors of means and variances of each qubit\"\n\n    nc = len(raw_data)  # the number of circuits used to generate the data\n    nq = len(raw_data[0])  # the number of qubits in each circuit\n    new_data = np.zeros([nc, 2 * nq])\n\n    for k, outcomes in enumerate(raw_data):\n        means = [np.mean(outcomes[q, :]) for q in range(nq)]\n        variances = [np.var(outcomes[q, :]) for q in range(nq)]\n        new_data[k] = np.array(means + variances)\n\n    return new_data\n\n\ndata = process_data(raw_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we use scikit-learn's [kernel\nPCA](https://en.wikipedia.org/wiki/Kernel_principal_component_analysis)\npackage to try and cluster the data. This performs principal component\nanalysis in a high dimensional feature space defined by a kernel (below\nwe use the radial basis function kernel).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import KernelPCA\nfrom sklearn import preprocessing\n\nkernel_pca = KernelPCA(\n    n_components=None, kernel=\"rbf\", gamma=None, fit_inverse_transform=True, alpha=0.1\n)\n\n# rescale the data so it has unit standard deviation and zero mean.\nscaler = preprocessing.StandardScaler().fit(data)\ndata = scaler.transform(data)\n# try to cluster the data\nfit = kernel_pca.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the result. Here we look at the first two principal\ncomponents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\n# make a colour map for the points\nc = np.array([0 for __ in range(circuits)] + [1 for __ in range(circuits)])\n\nplt.scatter(fit[:, 0], fit[:, 1], c=c)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks like the algorithm failed to cluster the data. We can try to get a\nseparation by increasing the number of shots. Let's increase the number\nof shots by 100 and see what happens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_shots = 10000  # 100 x more shots\n\nraw_data = []\n\nfor ts in [True, False]:\n    for __ in range(circuits):\n        circuit = generate_circuit(n_shots)\n        raw_data.append(circuit(ts=ts))\n\ndata = process_data(raw_data)\nscaler = preprocessing.StandardScaler().fit(data)\ndata = scaler.transform(data)\n\nfit = kernel_pca.fit(data).transform(data)\n\nplt.scatter(fit[:, 0], fit[:, 1], c=c)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have a separation, however we required a lot of shots from the\nquantum circuit. As we increase the number of qubits, the number of\nshots we need will scale exponentially (as shown in [\\[2\\]](#ref2)), and\nso conventional strategies cannot learn to separate the data\nefficiently.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The quantum-enhanced way\n========================\n\nNow let's see what difference having a quantum memory can make. Instead\nof using a single unitary to generate measurement data, we will make use\nof twice the number of qubits, and apply the unitary twice:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../demonstrations/learning_from_experiments/fig3b.png){.align-center\nwidth=\"70.0%\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In practice, this could be done by storing the output state from the\nfirst unitary in quantum memory and preparing the same state by using\nthe unitary again. Let's define a function `enhanced_circuit()` to\nimplement that. Note that since we now have twice as many qubits, we use\nhalf the number of shots as before so that the total number of uses of\nthe unitary is unchanged.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_shots = 50\nqubits = 8\n\ndev = qml.device(\"default.qubit\", wires=qubits * 2, shots=n_shots)\n\n\n@qml.qnode(dev)\ndef enhanced_circuit(ts=False):\n    \"implement the enhanced circuit, using a random unitary\"\n\n    if ts == True:\n        ops = [qml.RY]\n    else:\n        ops = [qml.RX, qml.RY, qml.RZ]\n\n    weights = np.random.rand(layers, n_shots) * np.pi\n    seed = np.random.randint(0, 10000)\n\n    for q in range(qubits):\n        qml.Hadamard(wires=q)\n\n    qml.broadcast(\n        qml.CNOT, pattern=[[q, qubits + q] for q in range(qubits)], wires=range(qubits * 2)\n    )\n    RandomLayers(weights, wires=range(0, qubits), rotations=ops, seed=seed)\n    RandomLayers(weights, wires=range(qubits, 2 * qubits), rotations=ops, seed=seed)\n    qml.broadcast(\n        qml.CNOT, pattern=[[q, qubits + q] for q in range(qubits)], wires=range(qubits * 2)\n    )\n\n    for q in range(qubits):\n        qml.Hadamard(wires=q)\n\n    return [qml.sample(op=qml.PauliZ(q)) for q in range(2 * qubits)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we generate some raw measurement data, and calculate the mean and\nvariance of each qubit as before. Our data vectors are now twice as long\nsince we have twice the number of qubits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw_data = []\n\nfor ts in [True, False]:\n    for __ in range(circuits):\n        raw_data.append(enhanced_circuit(ts))\n\ndata = process_data(raw_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's throw that into Kernel PCA again and plot the result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernel_pca = KernelPCA(\n    n_components=None, kernel=\"rbf\", gamma=None, fit_inverse_transform=True, alpha=0.1\n)\n\nscaler = preprocessing.StandardScaler().fit(data)\ndata = scaler.transform(data)\n\nfit = kernel_pca.fit(data).transform(data)\n\nc = np.array([0 for __ in range(circuits)] + [1 for __ in range(circuits)])\nplt.scatter(fit[:, 0], fit[:, 1], c=c)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kernel PCA has perfectly separated the two classes! In fact, all the\nT-symmetric unitaries have been mapped to the same point. This is\nbecause the circuit is actually equivalent to performing\n$U^TU\\otimes \\mathbb{I}\\vert 0 \\rangle$, which for T-symmetric unitaries\nis just the identity operation.\n\nTo see this, note that the Hadamard and CNOT gates before\n$U_i\\otimes U_i$ map the $\\vert0\\rangle$ state to the maximally entanged\nstate\n$\\vert \\Phi^+\\rangle = \\frac{1}{\\sqrt{2}}(\\vert 00...0\\rangle+ \\vert11...1\\rangle$,\nand the gates after $U_i\\otimes U_i$ are just the inverse\ntransformation. The probability that all measurement outcomes give the\nresult $+1$ is therefore.\n\n$$p(11\\cdots 1) = \\langle \\Phi^+ \\vert U_i \\otimes U_i \\vert\\Phi^+ \\rangle.$$\n\nA well known fact about the maximally entanged state is that\n$U\\otimes \\mathbb{I}\\vert\\Phi^+\\rangle= \\mathbb{I}\\otimes U^T\\vert\\Phi^+\\rangle$.\nThe probabilty is therefore\n\n$$p(11\\cdots 1) = \\langle \\Phi^+ \\vert U_i^T U_i \\otimes \\mathbb{I} \\vert\\Phi^+ \\rangle.$$\n\nFor T-symmetric unitaries $U_i^T=U_i^\\dagger$, so this probability is\nequal to one: the $11\\cdots 1$ outcome is always obtained.\n\nIf we look at the raw measurement data for the T-symmetric unitaries:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw_data[0][:, 0:5]  # outcomes of first 5 shots of the first T-symmetric circuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that indeed this is the only measurement outcome.\n\nTo make things a bit more interesting, let's add some noise to the\ncircuit. We will define a function `noise_layer(epsilon)` that adds some\nrandom single qubit rotations, where the maximum rotation angle is\n`epsilon`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def noise_layer(epsilon):\n    \"apply a random rotation to each qubit\"\n    for q in range(2 * qubits):\n        angles = (2 * np.random.rand(3) - 1) * epsilon\n        qml.Rot(angles[0], angles[1], angles[2], wires=q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We redefine our `enhanced_circuit()` function with a noise layer applied\nafter the unitaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev)\ndef enhanced_circuit(ts=False):\n    \"implement the enhanced circuit, using a random unitary with a noise layer\"\n\n    if ts == True:\n        ops = [qml.RY]\n    else:\n        ops = [qml.RX, qml.RY, qml.RZ]\n\n    weights = np.random.rand(layers, n_shots) * np.pi\n    seed = np.random.randint(0, 10000)\n\n    for q in range(qubits):\n        qml.Hadamard(wires=q)\n\n    qml.broadcast(\n        qml.CNOT, pattern=[[q, qubits + q] for q in range(qubits)], wires=range(qubits * 2)\n    )\n    RandomLayers(weights, wires=range(0, qubits), rotations=ops, seed=seed)\n    RandomLayers(weights, wires=range(qubits, 2 * qubits), rotations=ops, seed=seed)\n    noise_layer(np.pi / 4)  # added noise layer\n    qml.broadcast(\n        qml.CNOT, pattern=[[qubits + q, q] for q in range(qubits)], wires=range(qubits * 2)\n    )\n\n    for q in range(qubits):\n        qml.Hadamard(wires=qubits + q)\n\n    return [qml.sample(op=qml.PauliZ(q)) for q in range(2 * qubits)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we generate the data and feed it to kernel PCA again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw_data = []\n\nfor ts in [True, False]:\n    for __ in range(circuits):\n        raw_data.append(enhanced_circuit(ts))\n\ndata = process_data(raw_data)\n\nkernel_pca = KernelPCA(\n    n_components=None, kernel=\"rbf\", gamma=None, fit_inverse_transform=True, alpha=0.1\n)\nscaler = preprocessing.StandardScaler().fit(data)\ndata = scaler.transform(data)\nfit = kernel_pca.fit(data).transform(data)\n\nc = np.array([0 for __ in range(circuits)] + [1 for __ in range(circuits)])\nplt.scatter(fit[:, 0], fit[:, 1], c=c)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nice! Even in the presence of noise we still have a clean separation of\nthe two classes. This shows that using entanglement can make a big\ndifference to learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n==========\n\n\\[1\\] *Quantum advantage in learning from experiments*, Hsin-Yuan Huang\net. al., [arxiv:2112.00778](https://arxiv.org/pdf/2112.00778.pdf) (2021)\n\n\\[2\\] *Exponential separations between learning with and without quantum\nmemory*, Sitan Chen, Jordan Cotler, Hsin-Yuan Huang, Jerry Li,\n[arxiv:2111.05881](https://arxiv.org/abs/2111.05881) (2021)\n\nAbout the author\n================\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}